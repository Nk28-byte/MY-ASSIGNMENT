{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb/TeHFYj4BaUERnl64AUP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nk28-byte/MY-ASSIGNMENT/blob/main/Deep_Learning_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theoritical Questions"
      ],
      "metadata": {
        "id": "80D4wYIPt9xp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ques.1 What is tensorflow 2.0, and how is it different from tensorflow 1?\n",
        "\n",
        "Ans :- TensorFlow 2.0 represents a major upgrade over its predecessor, TensorFlow 1.x. It offers a more intuitive, user-friendly, and efficient approach to building and deploying machine learning models.\n",
        "\n",
        "Key Differences Between TensorFlow 1.x and TensorFlow 2.0:\n",
        "\n",
        "Eager Execution:\n",
        "\n",
        "TensorFlow 1.x: Relied on a static graph model, where you first defined the entire computation graph and then executed it within a session.\n",
        "TensorFlow 2.0: Introduces eager execution by default, allowing you to execute operations immediately as you write them. This makes debugging and experimentation much easier.\n",
        "Simplified API:\n",
        "\n",
        "TensorFlow 1.x: Had a complex and often verbose API, requiring users to manage sessions, placeholders, and feed dictionaries.\n",
        "TensorFlow 2.0: Offers a more streamlined and Pythonic API, reducing boilerplate code and making it easier to learn and use.\n",
        "Keras as the High-Level API:\n",
        "\n",
        "TensorFlow 1.x: Keras was a separate library that could be integrated with TensorFlow.\n",
        "TensorFlow 2.0: Keras is now the default high-level API, providing a user-friendly interface for building and training models.\n",
        "Functional and Sequential APIs:\n",
        "\n",
        "TensorFlow 2.0: Offers both functional and sequential APIs for building models, providing flexibility for different use cases.\n",
        "Improved Performance:\n",
        "\n",
        "TensorFlow 2.0: Incorporates optimizations and performance enhancements, leading to faster training and inference times.\n",
        "Better Integration with Other Tools:\n",
        "\n",
        "TensorFlow 2.0: Integrates seamlessly with other popular machine learning tools and frameworks, such as TensorFlow Lite, TensorFlow JS, and TensorFlow Hub.\n",
        "\n",
        "Ques.2 How do you install Tensorflow 2.0?\n",
        "\n",
        "Ans :- Prerequisites:\n",
        "\n",
        "Python: Ensure you have Python 3.7 or later installed. You can download the latest version from the official Python website: https://www.python.org/downloads/\n",
        "pip: This package installer is usually included with Python. You can verify its installation by running pip --version in your terminal.\n",
        "Installation Steps:\n",
        "\n",
        "Open your terminal or command prompt.\n",
        "\n",
        "Run the following command to install TensorFlow:\n",
        "\n",
        "Bash\n",
        "pip install tensorflow\n",
        "Use code with caution.\n",
        "\n",
        "Verifying the Installation:\n",
        "\n",
        "To confirm the installation, you can run a simple Python script:\n",
        "\n",
        "Python\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "Use code with caution.\n",
        "\n",
        "This should print the installed TensorFlow version.\n",
        "\n",
        "Additional Considerations for GPU Acceleration:\n",
        "\n",
        "If you have an NVIDIA GPU and want to leverage its power for faster training, you'll need to install the NVIDIA CUDA Toolkit and cuDNN. Follow the detailed instructions provided on the TensorFlow website for specific GPU setup: https://www.tensorflow.org/install/gpu\n",
        "\n",
        "\n",
        "Ques.3 What is the primary function of tensorflow in tensorflow 2.0?\n",
        "\n",
        "Ans :- The primary function of TensorFlow 2.0 is to build and train machine learning models, especially deep learning models. It provides a comprehensive ecosystem of tools and libraries to:\n",
        "\n",
        "Build models: You can use the Keras API to define complex neural network architectures, including convolutional neural networks (CNNs), recurrent neural networks (RNNs), and more.\n",
        "Train models: TensorFlow offers efficient optimization algorithms and loss functions to train models on large datasets.\n",
        "Deploy models: You can deploy your trained models to various platforms, including mobile devices, web browsers, and servers.\n",
        "Experiment and research: TensorFlow provides tools for experimentation, such as eager execution and custom training loops, to explore new ideas and techniques.\n",
        "Key features of TensorFlow 2.0 that support its primary function:\n",
        "\n",
        "Eager execution: This allows you to execute operations immediately, making debugging and experimentation easier.\n",
        "Keras as the high-level API: Keras provides a user-friendly interface for building and training models.\n",
        "Simplified API: The API is more intuitive and less verbose, making it easier to learn and use.\n",
        "Improved performance: TensorFlow 2.0 offers performance optimizations, making it faster to train and deploy models.\n",
        "Integration with other tools: TensorFlow integrates seamlessly with other popular machine learning tools and frameworks.\n",
        "\n",
        "Ques.4 What is the purpose of model class in tensorflow 2.0?\n",
        "\n",
        "Ans :- In TensorFlow 2.0, the Model class serves as a fundamental building block for creating and managing machine learning models, particularly deep neural networks. It provides a structured way to organize layers, define the model's architecture, and handle training and inference processes.\n",
        "\n",
        "Key Purposes of the Model Class:\n",
        "\n",
        "Organizing Layers:\n",
        "\n",
        "The Model class allows you to group layers into a hierarchical structure, making it easier to build complex models.\n",
        "Layers can be added sequentially, functionally, or through subclassing, providing flexibility in model design.\n",
        "Defining Model Architecture:\n",
        "\n",
        "By specifying the input and output layers, as well as the intermediate layers, you can define the model's architecture.\n",
        "This architecture determines how data flows through the model and how features are extracted and transformed.\n",
        "Training the Model:\n",
        "\n",
        "The Model class provides methods for compiling the model, which involves specifying the loss function, optimizer, and metrics.\n",
        "It also provides methods for training the model on a given dataset, adjusting the model's parameters to minimize the loss function.\n",
        "Making Predictions:\n",
        "\n",
        "Once the model is trained, it can be used to make predictions on new, unseen data.\n",
        "The Model class provides methods for making predictions, both on individual samples and on batches of data.\n",
        "Saving and Loading Models:\n",
        "\n",
        "The Model class offers methods for saving and loading models, allowing you to persist the model's architecture and weights.\n",
        "\n",
        "Ques.5 How do you create a neural network using Tensorflow?\n",
        "\n",
        "Ans :- ensorFlow 2.0, with its user-friendly Keras API, simplifies the process of creating neural networks. Here's a basic example of how to build a simple sequential neural network:\n",
        "\n",
        "Python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential([\n",
        "\n",
        "  Dense(12, activation='relu', input_shape=(10,)),\n",
        "  Dense(8, activation='relu'),\n",
        "  Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "Use code with caution.\n",
        "\n",
        "Breakdown of the Code:\n",
        "\n",
        "Import Necessary Libraries:\n",
        "\n",
        "tensorflow: The core library for machine learning.\n",
        "Sequential: A linear stack of layers.\n",
        "Dense: A densely connected neural layer.\n",
        "Create the Model:\n",
        "\n",
        "Sequential: Initializes a sequential model.\n",
        "Dense: Adds a densely connected layer with 12 neurons, ReLU activation, and an input shape of 10 features.\n",
        "More Dense layers are added, each with a different number of neurons and activation functions.\n",
        "Compile the Model:\n",
        "\n",
        "optimizer: Specifies the optimization algorithm (Adam in this case).\n",
        "loss: Defines the loss function to minimize (binary cross-entropy for binary classification).\n",
        "metrics: Specifies the metrics to monitor during training (accuracy).\n",
        "Train the Model:\n",
        "\n",
        "x_train: Training data input.\n",
        "y_train: Training data labels.\n",
        "epochs: Number of times to iterate over the entire dataset.\n",
        "batch_size: Number of samples processed before updating the model's parameters.\n",
        "\n",
        "Ques.6 What is the importance of tensorspace in tensorflow?\n",
        "\n",
        "Ans :- TensorSpace, a neural network 3D visualization framework built on TensorFlow.js, plays a crucial role in understanding and interpreting deep learning models. Here's why it's important:\n",
        "\n",
        "1. Visualizing Model Architecture:\n",
        "\n",
        "Intuitive Understanding: TensorSpace allows you to visualize the architecture of complex neural networks in 3D, making it easier to grasp the flow of information through the layers.\n",
        "Identifying Bottlenecks: By visualizing the model's structure, you can identify potential bottlenecks or inefficiencies that might be hindering performance.\n",
        "2. Understanding Feature Extraction:\n",
        "\n",
        "Feature Maps: TensorSpace can visualize the feature maps generated by convolutional layers, providing insights into how the model extracts and processes features from the input data.\n",
        "Feature Importance: By analyzing the feature maps, you can identify which features are most important for the model's decision-making process.\n",
        "3. Debugging and Troubleshooting:\n",
        "\n",
        "Identifying Errors: Visualizing the model's behavior can help you identify errors or unexpected behavior in the training process.\n",
        "Debugging Layer-wise: By inspecting the output of individual layers, you can pinpoint the source of problems and make necessary adjustments.\n",
        "4. Model Interpretability:\n",
        "\n",
        "Explaining Decisions: TensorSpace can help you understand why a model makes certain predictions by visualizing the flow of information through the network.\n",
        "Building Trust: By making the model's decision-making process more transparent, you can build trust in its predictions.\n",
        "5. Educational Tool:\n",
        "\n",
        "Learning Deep Learning: TensorSpace is a valuable tool for learning about deep learning concepts, as it provides a visual representation of how neural networks work.\n",
        "Teaching and Training: Educators can use TensorSpace to explain complex concepts to students in an engaging and interactive way.\n",
        "\n",
        "Ques.7 How can Tensorboard be integreated with tensorflow 2.0?\n",
        "\n",
        "Ans :- TensorBoard is a powerful visualization tool that can be seamlessly integrated with TensorFlow 2.0 to monitor and analyze your machine learning experiments. Here's a basic guide on how to integrate TensorBoard:\n",
        "\n",
        "1. Set Up TensorBoard Logging:\n",
        "\n",
        "Import Necessary Libraries:\n",
        "Python\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "Use code with caution.\n",
        "\n",
        "Create a TensorBoard Callback:\n",
        "Python\n",
        "tensorboard_callback = TensorBoard(log_dir='logs')\n",
        "Use code with caution.\n",
        "\n",
        "Log the Model's Training:\n",
        "Python\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
        "Use code with caution.\n",
        "\n",
        "2. Start TensorBoard:\n",
        "\n",
        "Navigate to the Log Directory: Open your terminal or command prompt and navigate to the directory where you specified the log_dir in the TensorBoard callback.\n",
        "Start TensorBoard: Run the following command:\n",
        "Bash\n",
        "tensorboard --logdir logs\n",
        "Use code with caution.\n",
        "\n",
        "Access TensorBoard: Open a web browser and go to http://localhost:6006 to access the TensorBoard dashboard.\n",
        "\n",
        "Ques.8 What is the purpose of tensorflow playground?\n",
        "\n",
        "Ans :- TensorFlow Playground is an interactive web-based tool that allows users to experiment with and learn about neural networks without requiring complex coding or mathematical knowledge. Its primary purpose is to provide a visual and intuitive understanding of how neural networks work.\n",
        "\n",
        "Key Purposes of TensorFlow Playground:\n",
        "\n",
        "Visualizing Neural Networks: It allows you to visualize the architecture of a neural network, including the number of layers, neurons, and connections between them.\n",
        "Understanding Training Process: You can observe the training process in real-time, seeing how the network learns from the data and adjusts its weights and biases.\n",
        "Experimenting with Hyperparameters: You can experiment with different hyperparameters like learning rate, activation function, and regularization techniques to see how they affect the network's performance.\n",
        "Exploring Different Datasets: You can test your neural network on various datasets, including simple classification and regression problems.\n",
        "Learning Fundamental Concepts: It helps you grasp fundamental concepts of neural networks, such as backpropagation, gradient descent, and overfitting.\n",
        "\n",
        "\n",
        "\n",
        " Ques.9 What is netron, and how is it useful for deep learning models?\n",
        "\n",
        " Ans :- Netron is a versatile visualization tool designed to help you understand the architecture and structure of various machine learning and deep learning models. It supports a wide range of model formats, including:\n",
        "\n",
        "Neural Network Frameworks: TensorFlow, PyTorch, ONNX, Keras, Core ML, Caffe, Darknet, MXNet\n",
        "Machine Learning Models: XGBoost, LightGBM, scikit-learn\n",
        "Other Formats: TensorFlow Lite, TensorFlow.js, TorchScript\n",
        "How Netron is Useful for Deep Learning Models:\n",
        "\n",
        "Visualizing Model Architecture:\n",
        "\n",
        "Netron allows you to visualize the layers, connections, and parameters of your deep learning models.\n",
        "You can easily see the flow of information through the network and identify potential bottlenecks or inefficiencies.\n",
        "Understanding Model Complexity:\n",
        "\n",
        "By visualizing the model's architecture, you can assess its complexity and identify areas where simplification might be possible.\n",
        "This can help you optimize the model's performance and reduce computational costs.\n",
        "Debugging Model Issues:\n",
        "\n",
        "Netron can help you identify errors or inconsistencies in your model's architecture.\n",
        "By visualizing the model, you can pinpoint the source of problems and make necessary adjustments.\n",
        "Sharing and Collaborating:\n",
        "\n",
        "Netron allows you to share your model's architecture with colleagues or collaborators, facilitating discussions and knowledge sharing.\n",
        "You can also use Netron to create presentations and tutorials to explain complex models to a wider audience.\n",
        "Learning and Experimentation:\n",
        "\n",
        "By visualizing different model architectures, you can learn about various deep learning techniques and experiment with different approaches.\n",
        "Netron can help you gain a deeper understanding of how neural networks work and how to design effective models.\n",
        "\n",
        "Ques.10 What is difference between tensorflow and pytorch?\n",
        "\n",
        "Ans :- TensorFlow and PyTorch are two of the most popular deep learning frameworks, each with its own strengths and weaknesses. Here's a comparison:\n",
        "\n",
        "Ease of Use:\n",
        "\n",
        "PyTorch: Often praised for its Pythonic nature and intuitive API, making it easier for beginners to learn and experiment with.\n",
        "TensorFlow: Can be more complex, especially for beginners, due to its static graph model. However, with the introduction of Keras as its high-level API, it has become more user-friendly.\n",
        "Flexibility and Dynamism:\n",
        "\n",
        "PyTorch: Highly flexible, allowing for dynamic computation graphs. This makes it ideal for research and prototyping, as you can modify models on the fly.\n",
        "TensorFlow: Traditionally, TensorFlow used static graphs, which required defining the entire computation graph before execution. However, with Eager Execution, it now offers more flexibility.\n",
        "Performance and Scalability:\n",
        "\n",
        "TensorFlow: Known for its performance and scalability, particularly in large-scale production environments. It offers features like distributed training and hardware acceleration.\n",
        "PyTorch: While not as optimized for large-scale production as TensorFlow, it has made significant strides in recent years, making it more suitable for production environments.\n",
        "Community and Ecosystem:\n",
        "\n",
        "TensorFlow: Has a large and active community, with extensive documentation, tutorials, and libraries. It's widely used in industry and academia.\n",
        "PyTorch: Also has a strong community, particularly in the research community. It's gaining popularity rapidly, especially among researchers and academics.\n",
        "\n",
        "Ques.11 How do you install pytorch?\n",
        "\n",
        "Ans :- To install PyTorch, you can follow these steps:\n",
        "\n",
        "1. Visit the Official PyTorch Website:\n",
        "\n",
        "Go to the PyTorch website: https://pytorch.org/\n",
        "Select your operating system (Windows, Linux, or macOS), Python version, and desired package installer (pip or conda).\n",
        "Choose your preferred CUDA version (if you have a compatible NVIDIA GPU) or CPU-only installation.\n",
        "2. Follow the Installation Instructions:\n",
        "\n",
        "The website will provide specific instructions tailored to your setup. Generally, you'll use one of the following methods:\n",
        "\n",
        "Using pip:\n",
        "\n",
        "Open your terminal or command prompt.\n",
        "Run the following command, replacing the placeholders with your specific requirements:\n",
        "Bash\n",
        "pip install torch torchvision torchaudio\n",
        "Use code with caution.\n",
        "\n",
        "Using conda:\n",
        "\n",
        "Open your Anaconda prompt.\n",
        "Run the following command:\n",
        "Bash\n",
        "conda install pytorch torchvision torchaudio cudatoolkit=<cuda_version> -c pytorch\n",
        "Use code with caution.\n",
        "Replace <cuda_version> with the appropriate CUDA version.\n",
        "3. Verify the Installation:\n",
        "\n",
        "After the installation is complete, you can verify it by running the following Python code:\n",
        "\n",
        "Python\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "Ques.12 What is the basic structure of pytorch neural network?\n",
        "\n",
        "Ans :- A PyTorch neural network typically consists of the following components:\n",
        "\n",
        "Data Loading and Preprocessing:\n",
        "\n",
        "Dataset Class: Defines how to load and preprocess data, including image, text, or tabular data.\n",
        "Data Loaders: Handles batching and shuffling of data.\n",
        "Data Transformations: Applies transformations like normalization, resizing, and augmentation to the data.\n",
        "Model Definition:\n",
        "\n",
        "Module Class: Inherits from nn.Module to create custom neural network modules.\n",
        "Layers: Uses various layers like nn.Linear, nn.Conv2d, nn.RNN, etc., to construct the network's architecture.\n",
        "Forward Pass: Defines the computation steps, taking input data and passing it through layers to produce output.\n",
        "Loss Function and Optimizer:\n",
        "\n",
        "Loss Function: Measures the difference between predicted and actual values (e.g., nn.CrossEntropyLoss, nn.MSELoss).\n",
        "Optimizer: Updates the model's parameters to minimize the loss (e.g., optim.SGD, optim.Adam).\n",
        "Training Loop:\n",
        "\n",
        "Iterate over Epochs: Repeats the training process multiple times.\n",
        "Forward Pass: Computes the model's output for a batch of data.\n",
        "Loss Calculation: Calculates the loss between the predicted and actual values.\n",
        "Backpropagation: Computes gradients of the loss with respect to the model's parameters.\n",
        "Parameter Update: Uses the optimizer to update the model's parameters based on the gradients.\n",
        "Evaluation and Testing:\n",
        "\n",
        "Evaluation: Assesses the model's performance on a validation dataset.\n",
        "Testing: Evaluates the final model's performance on a test dataset.\n",
        "\n",
        "Ques.13 What is significane of tensors in pytorch?\n",
        "\n",
        "Ans :- In PyTorch, tensors are the fundamental data structure used to represent and manipulate data. They are essentially multi-dimensional arrays, similar to NumPy arrays, but with the added advantage of GPU acceleration and automatic differentiation.\n",
        "\n",
        "Why are tensors so significant in PyTorch?\n",
        "\n",
        "Data Representation:\n",
        "\n",
        "Input Data: Tensors are used to represent input data, such as images, text, and numerical data.\n",
        "Model Parameters: The weights and biases of a neural network are also represented as tensors.\n",
        "Intermediate Results: Tensors store intermediate results during the forward and backward passes of a neural network.\n",
        "Efficient Computation:\n",
        "\n",
        "GPU Acceleration: PyTorch can leverage the power of GPUs to perform tensor operations much faster, accelerating the training process.\n",
        "Optimized Operations: PyTorch provides optimized implementations of common tensor operations, ensuring efficient computation.\n",
        "Automatic Differentiation:\n",
        "\n",
        "Gradient Calculation: PyTorch's automatic differentiation feature allows you to compute gradients of tensor operations with respect to other tensors. This is crucial for training neural networks using techniques like backpropagation.\n",
        "Optimizer Updates: The calculated gradients are used to update the model's parameters during the optimization process.\n",
        "Flexibility and Dynamic Computation Graphs:\n",
        "\n",
        "Dynamic Graphs: PyTorch's dynamic nature allows you to define and modify computation graphs on the fly, making it suitable for research and experimentation.\n",
        "Custom Operations: You can define custom operations on tensors to create complex and tailored neural network architectures.\n",
        "\n",
        "\n",
        "\n",
        "Quees.14 What is difference between in torch tensor and torch cuda tensor in pytorch?\n",
        "\n",
        "Ans :-In PyTorch, the primary difference between a torch.Tensor and a torch.cuda.Tensor lies in their underlying hardware and memory allocation.\n",
        "\n",
        "Torch Tensor:\n",
        "\n",
        "CPU-based: These tensors are stored and processed on the CPU.\n",
        "Slower for large-scale computations: While suitable for smaller models and datasets, they can become a bottleneck for larger models or when real-time performance is crucial.\n",
        "Torch CUDA Tensor:\n",
        "\n",
        "GPU-based: These tensors are stored and processed on the GPU.\n",
        "Faster for large-scale computations: GPUs are highly parallel processors designed for numerical computations, making them significantly faster than CPUs for tasks like matrix operations and deep learning.\n",
        "Key Differences:\n",
        "\n",
        "Feature\tTorch Tensor\tTorch CUDA Tensor\n",
        "Hardware\tCPU\tGPU\n",
        "Memory Location\tCPU memory\tGPU memory\n",
        "Performance\tSlower for large-scale computations\tFaster for large-scale computations\n",
        "\n",
        "Export to Sheets\n",
        "When to Use Which:\n",
        "\n",
        "Torch Tensor:\n",
        "Smaller models or datasets.\n",
        "When GPU acceleration is not available or not necessary.\n",
        "For debugging and prototyping.\n",
        "Torch CUDA Tensor:\n",
        "Large-scale models and datasets.\n",
        "When real-time performance is critical.\n",
        "\n",
        "Ques.15 what is the purpose of torch optim module in pytorch?\n",
        "\n",
        "Ans :- The torch.optim module in PyTorch is a powerful tool for optimizing the parameters of neural networks. It provides various optimization algorithms that are essential for training models effectively.\n",
        "\n",
        "Key Purpose:\n",
        "\n",
        "The primary purpose of torch.optim is to minimize the loss function associated with a neural network by adjusting its parameters (weights and biases). This is achieved through a process called gradient descent, where the gradients of the loss function with respect to the parameters are computed and used to update the parameters in the direction of minimizing the loss.\n",
        "\n",
        "Common Optimization Algorithms in torch.optim:\n",
        "\n",
        "SGD (Stochastic Gradient Descent):\n",
        "A basic optimization algorithm that updates parameters in the direction of the negative gradient.\n",
        "Simple to implement but can be slow to converge.\n",
        "Momentum:\n",
        "Adds momentum to the parameter updates, accelerating convergence and reducing oscillations.\n",
        "AdaGrad:\n",
        "Adapts the learning rate for each parameter, reducing the learning rate for parameters that have already been updated significantly.\n",
        "RMSprop:\n",
        "Similar to AdaGrad but uses a decaying average of squared gradients to adapt the learning rate.\n",
        "Adam:\n",
        "Combines the advantages of Momentum and RMSprop, making it a popular choice for many neural network architectures.\n",
        "\n",
        "Ques.16 What are some common activation functions used in neural networks?\n",
        "\n",
        "Ans :- Here are some of the most common activation functions used in neural networks:\n",
        "\n",
        "1. ReLU (Rectified Linear Unit):\n",
        "\n",
        "Formula: f(x) = max(0, x)\n",
        "Advantages: Simple, efficient to compute, and helps with the vanishing gradient problem.\n",
        "Disadvantages: Can suffer from the \"dying ReLU\" problem, where neurons can become inactive.\n",
        "2. Leaky ReLU:\n",
        "\n",
        "Formula: f(x) = max(αx, x)\n",
        "Advantages: Addresses the \"dying ReLU\" problem by allowing a small gradient for negative inputs.\n",
        "Disadvantages: The choice of the α parameter can be critical.\n",
        "3. Parametric ReLU (PReLU):\n",
        "\n",
        "Formula: f(x) = max(αx, x)\n",
        "Advantages: Similar to Leaky ReLU, but the α parameter is learned during training.\n",
        "Disadvantages: Can be more computationally expensive.\n",
        "4. ELU (Exponential Linear Unit):\n",
        "\n",
        "Formula: f(x) = { x, if x > 0; α(exp(x) - 1), otherwise }\n",
        "Advantages: Can help with the vanishing gradient problem and can learn negative values.\n",
        "Disadvantages: Can be more computationally expensive than ReLU.\n",
        "5. Sigmoid:\n",
        "\n",
        "Formula: f(x) = 1 / (1 + exp(-x))\n",
        "Advantages: Outputs values between 0 and 1, making it suitable for probabilities.\n",
        "Disadvantages: Can suffer from the vanishing gradient problem and is not zero-centered.\n",
        "6. Tanh (Hyperbolic Tangent):\n",
        "\n",
        "Formula: f(x) = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "Advantages: Outputs values between -1 and 1, making it zero-centered.\n",
        "Disadvantages: Can still suffer from the vanishing gradient problem.\n",
        "7. Softmax:\n",
        "\n",
        "Used for multi-class classification problems.\n",
        "Converts a vector of real numbers into a probability distribution.\n",
        "Often used in the output layer of neural networks.\n",
        "\n",
        "Ques.17 What is difference between torch nn module and torch nn sequential in pytorch?\n",
        "\n",
        "Ans :- Torch.nn.Module vs. Torch.nn.Sequential\n",
        "\n",
        "In PyTorch, both torch.nn.Module and torch.nn.Sequential are fundamental building blocks for creating neural network models. However, they differ in their structure and flexibility.\n",
        "\n",
        "Torch.nn.Module:\n",
        "\n",
        "Flexibility: Provides a flexible way to define complex neural network architectures.\n",
        "Customizable: You can create custom modules with arbitrary forward pass logic.\n",
        "Hierarchical Structure: Allows for hierarchical organization of layers, making it suitable for complex models.\n",
        "Manual Forward Pass: You need to define the forward pass explicitly in the forward method.\n",
        "Example:\n",
        "\n",
        "Python\n",
        "import torch.nn as nn\n",
        "\n",
        "class MyModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.linear1 = nn.Linear(10, 1\n",
        "1.\n",
        "github.com\n",
        "github.com\n",
        " 20)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(20, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "Use code with caution.\n",
        "\n",
        "Torch.nn.Sequential:\n",
        "\n",
        "Simplicity: A simpler way to define sequential neural networks.\n",
        "Sequential Structure: Layers are added sequentially, making it suitable for simple feedforward networks.\n",
        "Automatic Forward Pass: The forward pass is defined implicitly by the order of layers.\n",
        "Example:\n",
        "\n",
        "Python\n",
        "import torch.nn as nn\n",
        "\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "Use code with caution.\n",
        "\n",
        "Key Differences:\n",
        "\n",
        "Flexibility: nn.Module offers more flexibility for complex architectures.\n",
        "Simplicity: nn.Sequential is simpler for sequential models.\n",
        "Forward Pass: nn.Module requires explicit definition, while nn.Sequential defines it implicitly.\n",
        "\n",
        "Ques.18 How does keras API fit into tensorflow 2.0?\n",
        "\n",
        "Ans :- In TensorFlow 2.0, Keras has been seamlessly integrated as the high-level API, making it the preferred way to build and train deep learning models. This integration offers several advantages:\n",
        "\n",
        "1. User-Friendly Interface:\n",
        "\n",
        "Simplified Syntax: Keras provides a more intuitive and concise syntax for defining models, compiling them, and training them.\n",
        "Reduced Boilerplate Code: Keras handles many low-level details, allowing developers to focus on the core model architecture.\n",
        "2. Rapid Prototyping:\n",
        "\n",
        "Quick Experimentation: Keras' modular approach enables rapid experimentation with different architectures and hyperparameters.\n",
        "Faster Development Cycles: The simplified API reduces development time, accelerating the iterative process of model building and refinement.\n",
        "3. Seamless Integration with TensorFlow Ecosystem:\n",
        "\n",
        "Leveraging TensorFlow's Power: Keras models can access the full power of TensorFlow's backend, including optimized operations, GPU acceleration, and distributed training.\n",
        "Compatibility with TensorFlow's Tools: Keras models can be easily integrated with TensorFlow's tools like TensorBoard for visualization and profiling.\n",
        "4. Flexibility and Customization:\n",
        "\n",
        "Custom Layers and Models: Keras allows you to create custom layers and models, providing flexibility for advanced use cases.\n",
        "Integration with Other Libraries: Keras can be combined with other libraries like OpenCV and scikit-learn for data preprocessing and post-processing.\n",
        "\n",
        "\n",
        "\n",
        "Ques.18 How can you monitor training progress in tensorflow 2.0?\n",
        "\n",
        " Ans :- ensorFlow 2.0 offers several methods to monitor training progress:\n",
        "\n",
        "1. Built-in Progress Bar:\n",
        "\n",
        "When you use model.fit(), a progress bar is automatically displayed, showing the current epoch, batch, loss, and other metrics.\n",
        "2. TensorBoard:\n",
        "\n",
        "A powerful visualization tool to monitor various aspects of training:\n",
        "Scalars: Visualize scalar metrics like loss, accuracy, learning rate, etc., over epochs.\n",
        "Images: View generated images during training.\n",
        "Histograms: Analyze the distribution of weights and activations.\n",
        "Graphs: Explore the model's computational graph.\n",
        "Embeddings: Visualize high-dimensional embeddings in a lower-dimensional space.\n",
        "Profiler: Analyze the performance of your model and identify bottlenecks.\n",
        "\n",
        "To use TensorBoard:\n",
        "\n",
        "Import the TensorBoard callback:\n",
        "Python\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "Use code with caution.\n",
        "\n",
        "Create a TensorBoard instance:\n",
        "Python\n",
        "tensorboard_callback = TensorBoard(log_dir='logs')\n",
        "Use code with caution.\n",
        "\n",
        "Pass the callback to the fit() method:\n",
        "Python\n",
        "model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
        "Use code with caution.\n",
        "\n",
        "Start TensorBoard:\n",
        "Bash\n",
        "tensorboard --logdir logs\n",
        "Use code with caution.\n",
        "\n",
        "Open your web browser and go to http://localhost:6006 to view the dashboard\n",
        "\n",
        "Ques.20 What is an example of deep learning projects that canbe implemented using tensorflow 2.0?\n",
        "\n",
        "Ans :- Here are a few examples of deep learning projects that can be implemented using TensorFlow 2.0:\n",
        "\n",
        "1. Image Classification:\n",
        "\n",
        "Task: Classifying images into different categories (e.g., cats vs. dogs, different types of flowers).\n",
        "Model: Convolutional Neural Networks (CNNs) like ResNet, VGG, or Inception.\n",
        "Applications: Image search engines, medical image analysis, autonomous vehicles.\n",
        "2. Object Detection:\n",
        "\n",
        "Task: Identifying and locating objects within images (e.g., detecting cars, pedestrians, and traffic signs in self-driving car scenarios).\n",
        "Model: Object Detection models like Faster R-CNN, YOLO, or SSD.\n",
        "Applications: Self-driving cars, surveillance systems, robotics.\n",
        "3. Natural Language Processing (NLP):\n",
        "\n",
        "Task: Processing and understanding human language (e.g., sentiment analysis, text classification, machine translation).\n",
        "Model: Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, or Transformer models like BERT.\n",
        "Applications: Chatbots, language translation, text summarization.\n",
        "4. Generative Models:\n",
        "\n",
        "Task: Generating new data samples (e.g., images, text, music).\n",
        "Model: Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs).\n",
        "Applications: Image generation, data augmentation, style transfer.\n",
        "5. Time Series Forecasting:\n",
        "\n",
        "Task: Predicting future values of a time series (e.g., stock prices, weather patterns).\n",
        "Model: Recurrent Neural Networks (RNNs) or specialized time series models like LSTM or GRU.\n",
        "Applications: Financial forecasting, weather prediction, energy load forecasting.\n",
        "6. Reinforcement Learning:\n",
        "\n",
        "Task: Training agents to make decisions in an environment to maximize rewards (e.g., playing games, controlling robots).\n",
        "Model: Deep Q-Networks (DQNs), Policy Gradient methods.\n",
        "Applications: Game AI, robotics, autonomous systems.\n",
        "\n",
        "Ques.21 What is the main advantage of using pre-trained models in tensorflow and pytorch?\n",
        "\n",
        "Ans :- Advantages of Using Pre-trained Models in TensorFlow and PyTorch\n",
        "Pre-trained models offer several significant advantages when working with deep learning frameworks like TensorFlow and PyTorch:\n",
        "\n",
        "1. Faster Training:\n",
        "\n",
        "Reduced Training Time: Pre-trained models have already been trained on massive datasets, saving you significant time and computational resources.\n",
        "Quicker Model Development: By leveraging pre-trained models, you can quickly prototype and iterate on your ideas.\n",
        "2. Improved Performance:\n",
        "\n",
        "State-of-the-Art Performance: Pre-trained models often achieve state-of-the-art performance on specific tasks, providing a solid foundation for your own models.\n",
        "Better Generalization: These models have learned rich feature representations from large datasets, which can improve the generalization ability of your model, especially when working with limited data.\n",
        "3. Reduced Data Requirements:\n",
        "\n",
        "Fewer Training Data: Pre-trained models can be fine-tuned on smaller datasets, making them suitable for scenarios where large datasets are not available.\n",
        "Improved Performance with Limited Data: Even with limited data, fine-tuning a pre-trained model can often yield better results than training a model from scratch.\n",
        "4. Transfer Learning:\n",
        "\n",
        "Knowledge Transfer: Pre-trained models can transfer knowledge learned from one task to another related task.\n",
        "Adaptability: This makes them highly adaptable to various domains and applications.\n",
        "5. Access to Advanced Models:\n",
        "\n",
        "Cutting-Edge Models: Pre-trained models often incorporate the latest advancements in deep learning, providing access to sophisticated architectures and techniques.\n",
        "Easy to Use: These models are often packaged and distributed in user-friendly formats, making them easy to integrate into your projects.\n"
      ],
      "metadata": {
        "id": "Ar2V4nBvd7xN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "ULX2UA1om89A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jppbeotbKIG",
        "outputId": "ee598669-efaf-41a8-dc45-5becaf8dc3bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.1\n"
          ]
        }
      ],
      "source": [
        "# Q.1 How do you install and verify that tensorflow 2.0  was installed succesfully?\n",
        "# Ans :-\n",
        "# pip install tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# pip install tensorflow==2.0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ques.2 How can you define a simple function in tensorflow 2.0 to perfrom addition?\n",
        "# Ans :-\n",
        "import tensorflow as tf\n",
        "\n",
        "def add(x, y):\n",
        "  return x + y\n",
        "\n",
        "# Example usage:\n",
        "a = tf.constant(2)\n",
        "b = tf.constant(3)\n",
        "\n",
        "result = add(a, b)\n",
        "print(result)  # Output: tf.Tensor(5, shape=(), dtype=int32)\n",
        "\n",
        "@tf.function\n",
        "def add(x, y):\n",
        "  return x + y\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27on-B0Mn6ub",
        "outputId": "b7b8c6c2-dec6-4d1f-b681-04f9d96aeeff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(5, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques.3 How can you create a simple neural network in tensorflow 2.0 with one hidde layer/\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense\n",
        "\n",
        "# # Create a Sequential model\n",
        "# model = Sequential([\n",
        "#     Dense(12, activation='relu', input_shape=(784,)),  # Input layer\n",
        "#     Dense(10, activation='softmax')  # Output layer\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(x_train, y_train, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "id": "pFsb6RTOodbL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques.4 How can you visualize the training progress using tensorflow  and matplotlib?\n",
        "# # Visualizing Training Progress with TensorFlow and Matplotlib\n",
        "\n",
        "# from tensorflow.keras.callbacks import TensorBoard\n",
        "# tensorboard_callback = TensorBoard(log_dir='logs')\n",
        "# model.fit(x_train, y_train, epochs=10, callbacks=[tensorboard_callback])\n",
        "# # tensorboard --logdir logs\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Assuming you have training history stored in a variable `history`\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('Model Loss')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('Model Accuracy')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "KWIpK0Who7me"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques. How do you install pytorch and verify the pytorch installation?\n",
        "# # Installing PyTorch\n",
        "\n",
        "# # 1. Visit the Official PyTorch Website:\n",
        "\n",
        "# # Go to the PyTorch website: https://pytorch.org/\n",
        "# # Select your operating system (Windows, Linux, or macOS), Python version, and desired package installer (pip or conda).\n",
        "# # Choose your preferred CUDA version (if you have a compatible NVIDIA GPU) or CPU-only installation.\n",
        "# # 2. Follow the Installation Instructions:\n",
        "\n",
        "# # The website will provide specific instructions tailored to your setup. Generally, you'll use one of the following methods:\n",
        "\n",
        "# # Using pip:\n",
        "\n",
        "# # Open your terminal or command prompt.\n",
        "\n",
        "# # Run the following command, replacing the placeholders with your specific requirements:\n",
        "\n",
        "# # Bash\n",
        "# pip install torch torchvision torchaudio\n",
        "\n",
        "# # Using conda:\n",
        "\n",
        "# # Open your Anaconda prompt.\n",
        "\n",
        "# # Run the following command:\n",
        "\n",
        "# # Bash\n",
        "# conda install pytorch torchvision torchaudio cudatoolkit=<cuda_version> -c pytorch\n",
        "\n",
        "\n",
        "# Replace <cuda_version> with the appropriate CUDA version.\n",
        "\n",
        "# # Verifying the Installation:\n",
        "\n",
        "# # After the installation is complete, you can verify it by running the following Python code:\n",
        "\n",
        "# # Python\n",
        "# import torch\n",
        "# print(torch.__version__)\n",
        "# # Use code with caution.\n",
        "\n",
        "# # This should print the installed PyTorch version.\n",
        "# #\n",
        "# # Additional Tips:\n",
        "\n",
        "# # Virtual Environments: It's recommended to use virtual environments to isolate your PyTorch installation from other projects.\n",
        "# # CUDA and GPU Support: If you have an NVIDIA GPU, installing the appropriate CUDA toolkit is crucial for GPU acceleration.\n",
        "# # Additional Packages: You might need to install additional packages like NumPy and Matplotlib for data processing and visualization."
      ],
      "metadata": {
        "id": "OTXvLa5ipU89"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques.6 How do you create a simple neural network in pytorch?\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# # Define a simple neural network\n",
        "# class SimpleNet(nn.Module):\n",
        "#     def __init__(self, input_size, hidden_size, output_size):\n",
        "#         super(SimpleNet, self).__init__()\n",
        "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n",
        "# # Create an instance of the model\n",
        "# model = SimpleNet(input_size=784, hidden_size=50, output_size=10)\n",
        "\n",
        "# # Define loss function and optimizer\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# # Training loop (simplified)\n",
        "# for epoch in range(10):\n",
        "#     for inputs, labels in data_loader:\n",
        "#         # Forward pass\n",
        "#         outputs = model(inputs)\n",
        "#         loss = criterion(outputs, labels)\n",
        "\n",
        "#         # Backward pass and optimization\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()"
      ],
      "metadata": {
        "id": "j1jp96ZEpvi9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques.7 How do you define a loss function and optimizer in pytorch?\n",
        "# In PyTorch, loss functions and optimizers are essential components for training neural networks.\n",
        "\n",
        "# Loss Functions\n",
        "# Loss functions measure the discrepancy between the model's predictions and the ground truth labels. PyTorch provides a variety of loss functions in the torch.nn module. Here are some common ones\n",
        "\n",
        "# 1. Cross-Entropy Loss:\n",
        "\n",
        "# Used for classification tasks.\n",
        "# Suitable for both binary and multi-class classification.\n",
        "# Python\n",
        "# import torch.nn as nn\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# Use code with caution.\n",
        "\n",
        "# 2. Mean Squared Error (MSE):\n",
        "\n",
        "# Used for regression tasks.\n",
        "# Measures the average squared difference between the predicted and true values.\n",
        "# Python\n",
        "# criterion = nn.MSELoss()\n",
        "# Use code with caution.\n",
        "\n",
        "# 3. Mean Absolute Error (MAE):\n",
        "\n",
        "# Used for regression tasks.\n",
        "# Measures the average absolute difference between the predicted and true values.\n",
        "# Python\n",
        "# criterion = nn.L1Loss()\n",
        "# Use code with caution.\n",
        "\n",
        "# Optimizers\n",
        "# Optimizers update the model's parameters to minimize the loss function. PyTorch provides several optimization algorithms in the torch.optim module. Here are some commonly used ones:\n",
        "\n",
        "# 1. Stochastic Gradient Descent (SGD):\n",
        "\n",
        "# A basic optimization algorithm that updates parameters in the direction of the negative gradient.\n",
        "# Python\n",
        "# import torch.optim as optim\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "# Use code with caution.\n",
        "\n",
        "# 2. Adam:\n",
        "\n",
        "# A popular optimization algorithm that combines the advantages of Momentum and RMSprop.\n",
        "# Python\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# Use code with caution.\n",
        "\n",
        "# 3. RMSprop:\n",
        "\n",
        "# An optimization algorithm that divides the gradient by an exponentially decaying average of squared gradients.\n",
        "# Python\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "T6sS7THYqGdI"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques.8 How do you implement a custom loss function in pytorch?\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class CustomLoss(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(CustomLoss, self).__init__()\n",
        "\n",
        "#     def forward(self, output, target):\n",
        "#         # Calculate the loss based on your custom logic\n",
        "#         loss = torch.mean((output - target)**2)  # Example: Mean Squared Error\n",
        "#         return loss\n",
        "#         criterion = CustomLoss()\n",
        "#         # ... (Forward pass)\n",
        "# loss = criterion(output, target)\n",
        "\n",
        "# # ... (Backward pass and optimization)\n",
        "\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class DiceLoss(nn.Module):\n",
        "#     def __init__(self, smooth=1.0):\n",
        "#         super(DiceLoss, self).__init__()\n",
        "#         self.smooth = smooth\n",
        "\n",
        "#     def forward(self, output, target):\n",
        "#         intersection = (output * target).sum(dim=(2, 3))\n",
        "#         union = (output + target).sum(dim=(2, 3))\n",
        "#         dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
        "#         loss = 1 - dice.mean()\n",
        "#         return loss\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Opb_FiU2qdsE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Ques.9 How do you save and load a tensorflow model?\n",
        "# import tensorflow as tf\n",
        "\n",
        "# # ... (Model training code)\n",
        "\n",
        "# # Save the entire model\n",
        "# model.save('my_model.h5')\n",
        "\n",
        "# # Load the saved model\n",
        "# loaded_model = tf.keras.models.load_model('my_model.h5')\n",
        "\n",
        "# # Save only the model weights\n",
        "# model.save_weights('model_weights.h5')\n",
        "\n",
        "# # Load the model weights\n",
        "# model.load_weights('model_weights.h5')\n",
        "\n",
        "# # Save the model architecture\n",
        "# model.save('model_architecture.json')\n",
        "\n",
        "# # Load the model architecture\n",
        "# with open('model_architecture.json') as json_file:\n",
        "#     json_string = json_file.read()\n",
        "# model = tf.keras.models.model_from_json(json_string)\n",
        "\n"
      ],
      "metadata": {
        "id": "XDgyP-kGq-Gl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O3dyMTw5rWEU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}