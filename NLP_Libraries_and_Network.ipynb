{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGQSrNAnaIXnAJenRUORfz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9919d370bf77454ca2456cb503b3f3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97ae732e8e1c475aa1b29fdfe2ce11b3",
              "IPY_MODEL_4a2a5a89c6c9496ca7c9c5ad05401e00",
              "IPY_MODEL_35ef22acfa444cdcb6de750e1b45fbba"
            ],
            "layout": "IPY_MODEL_a73a2ffdf2a64f00a6828e39be66050c"
          }
        },
        "97ae732e8e1c475aa1b29fdfe2ce11b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29ead09ae66f4e068aca6a3931903189",
            "placeholder": "​",
            "style": "IPY_MODEL_b37cbb5babc240bd95f360151f93e125",
            "value": "config.json: 100%"
          }
        },
        "4a2a5a89c6c9496ca7c9c5ad05401e00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286847bf3c624c5a852591e83a4e176f",
            "max": 483,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91785c6561d942ca8c1a8009fc948533",
            "value": 483
          }
        },
        "35ef22acfa444cdcb6de750e1b45fbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27cdfea763de4272ae8684c5f8f3a144",
            "placeholder": "​",
            "style": "IPY_MODEL_7431c3e6660844c7bd9ccd2b6dd39899",
            "value": " 483/483 [00:00&lt;00:00, 6.48kB/s]"
          }
        },
        "a73a2ffdf2a64f00a6828e39be66050c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ead09ae66f4e068aca6a3931903189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b37cbb5babc240bd95f360151f93e125": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "286847bf3c624c5a852591e83a4e176f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91785c6561d942ca8c1a8009fc948533": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27cdfea763de4272ae8684c5f8f3a144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7431c3e6660844c7bd9ccd2b6dd39899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa9df90f7d8042ba867341e2a4df3592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da24a7f47ac6448e88ef54d17ba94f64",
              "IPY_MODEL_eca786267c6a4026af4db45362c2696e",
              "IPY_MODEL_042584ff8af544f0bcf090fbe83b8dc3"
            ],
            "layout": "IPY_MODEL_7a1711075b014c49ad9f4b44879d5d74"
          }
        },
        "da24a7f47ac6448e88ef54d17ba94f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4a9e55cad524d2f86001e1e961ac14e",
            "placeholder": "​",
            "style": "IPY_MODEL_1f6cd44629544f519306e0430768e8ff",
            "value": "model.safetensors: 100%"
          }
        },
        "eca786267c6a4026af4db45362c2696e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4aa67b4948d54baba4872aa3a7a2c631",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a3389aaf1c74526af5d3e5a32315fc6",
            "value": 267954768
          }
        },
        "042584ff8af544f0bcf090fbe83b8dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a723d57c33f4a329f612e92092e7465",
            "placeholder": "​",
            "style": "IPY_MODEL_6040bf80727c4b1e8db0d298061b1626",
            "value": " 268M/268M [00:03&lt;00:00, 88.7MB/s]"
          }
        },
        "7a1711075b014c49ad9f4b44879d5d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4a9e55cad524d2f86001e1e961ac14e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f6cd44629544f519306e0430768e8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4aa67b4948d54baba4872aa3a7a2c631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3389aaf1c74526af5d3e5a32315fc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a723d57c33f4a329f612e92092e7465": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6040bf80727c4b1e8db0d298061b1626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d399c5262a043729ff13bcb1b5a9662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8916c90cfca4b9db76665bd86ba05e1",
              "IPY_MODEL_569a7256cfaf47edbfdf3bf22a559a26",
              "IPY_MODEL_325dd91db43245c59f1b25fec4e6a040"
            ],
            "layout": "IPY_MODEL_ce28d00b5aca4f95a97980c22df9eb3f"
          }
        },
        "c8916c90cfca4b9db76665bd86ba05e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7916d2b2fe4f6d9978ad85163c3c64",
            "placeholder": "​",
            "style": "IPY_MODEL_3837d93445d04809a3cd36b04d71808a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "569a7256cfaf47edbfdf3bf22a559a26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf5b5f4197a4bd9ab3b0fed55c2ddf4",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2de53edf10547148d7d3a6f917dacfa",
            "value": 48
          }
        },
        "325dd91db43245c59f1b25fec4e6a040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4e01d72b4f84587a8c619d5497931eb",
            "placeholder": "​",
            "style": "IPY_MODEL_122229d0055347529c03902237cfbb67",
            "value": " 48.0/48.0 [00:00&lt;00:00, 564B/s]"
          }
        },
        "ce28d00b5aca4f95a97980c22df9eb3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7916d2b2fe4f6d9978ad85163c3c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3837d93445d04809a3cd36b04d71808a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dbf5b5f4197a4bd9ab3b0fed55c2ddf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2de53edf10547148d7d3a6f917dacfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4e01d72b4f84587a8c619d5497931eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "122229d0055347529c03902237cfbb67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b6d17238fc54adb96c0423e80566843": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_754ac8ddc79546fb8ea41cbf4f9270de",
              "IPY_MODEL_c43f930284e948bf9c9d8c97672a0ca2",
              "IPY_MODEL_c2258a16cc7e407a92d333ec6ba87ba2"
            ],
            "layout": "IPY_MODEL_7c5d6d5dd1f94f12b01df410a56e3e26"
          }
        },
        "754ac8ddc79546fb8ea41cbf4f9270de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa44cb14b2d84dbe8da009a927be49d7",
            "placeholder": "​",
            "style": "IPY_MODEL_dcad56e7f7234b16994423b454130f99",
            "value": "vocab.txt: 100%"
          }
        },
        "c43f930284e948bf9c9d8c97672a0ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e915531ac587491cb9a652f94090daf2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec70875819b3447a9c7be5a20c304b34",
            "value": 231508
          }
        },
        "c2258a16cc7e407a92d333ec6ba87ba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f506e7a1976a44f49d35e953a337ae09",
            "placeholder": "​",
            "style": "IPY_MODEL_cea0baa7407444819a81481e1729c092",
            "value": " 232k/232k [00:00&lt;00:00, 2.61MB/s]"
          }
        },
        "7c5d6d5dd1f94f12b01df410a56e3e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa44cb14b2d84dbe8da009a927be49d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcad56e7f7234b16994423b454130f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e915531ac587491cb9a652f94090daf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec70875819b3447a9c7be5a20c304b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f506e7a1976a44f49d35e953a337ae09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea0baa7407444819a81481e1729c092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069bb4a698144f3f945c87e12064c37b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3a7f9ca0e551433597916ad2e944c9fe",
              "IPY_MODEL_035c23a14d3742adb9ce30d2adda1137",
              "IPY_MODEL_0320382985fd458f8d875ea7352b4eb5"
            ],
            "layout": "IPY_MODEL_e6d4cc5a8cd9485fa45802e9a6738868"
          }
        },
        "3a7f9ca0e551433597916ad2e944c9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0e45e692ec470ca950f9f9aa52027a",
            "placeholder": "​",
            "style": "IPY_MODEL_4d551c0811de4b458c5e31476a5f5eb5",
            "value": "tokenizer.json: 100%"
          }
        },
        "035c23a14d3742adb9ce30d2adda1137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22684a2d9ed044cdb200f73becaed6c7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8453ea149b24f11ab014a59afafca3e",
            "value": 466062
          }
        },
        "0320382985fd458f8d875ea7352b4eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54b2b47ab9374a37ab9fa3001d3db61b",
            "placeholder": "​",
            "style": "IPY_MODEL_72c5086c83e74de7a90f6462de0ca04e",
            "value": " 466k/466k [00:00&lt;00:00, 2.25MB/s]"
          }
        },
        "e6d4cc5a8cd9485fa45802e9a6738868": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0e45e692ec470ca950f9f9aa52027a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d551c0811de4b458c5e31476a5f5eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22684a2d9ed044cdb200f73becaed6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8453ea149b24f11ab014a59afafca3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54b2b47ab9374a37ab9fa3001d3db61b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72c5086c83e74de7a90f6462de0ca04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce8d99d0796349bbbe932311e4687bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_becd8c83a91e4383ba8a36c06947ccc8",
              "IPY_MODEL_d5b2671174ee4527a894347a265b6886",
              "IPY_MODEL_64bfaca9eed74be8ae81d471a9a2332b"
            ],
            "layout": "IPY_MODEL_3fb6c9a8f46241d6b87b9f167bc26b90"
          }
        },
        "becd8c83a91e4383ba8a36c06947ccc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f753a98c95e04182bad06600879eaebc",
            "placeholder": "​",
            "style": "IPY_MODEL_432e0989bcf2477b8d164277f37538b3",
            "value": "config.json: 100%"
          }
        },
        "d5b2671174ee4527a894347a265b6886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac47dd07d62b44d59851c8547c0219d0",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d577159b477f4b4c81b43a2098a29e73",
            "value": 570
          }
        },
        "64bfaca9eed74be8ae81d471a9a2332b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb40afe9d5e6421dbde8f0d91094506a",
            "placeholder": "​",
            "style": "IPY_MODEL_b9e57ab9134f45f4a95a5a12de682d84",
            "value": " 570/570 [00:00&lt;00:00, 12.8kB/s]"
          }
        },
        "3fb6c9a8f46241d6b87b9f167bc26b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f753a98c95e04182bad06600879eaebc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "432e0989bcf2477b8d164277f37538b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac47dd07d62b44d59851c8547c0219d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d577159b477f4b4c81b43a2098a29e73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb40afe9d5e6421dbde8f0d91094506a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e57ab9134f45f4a95a5a12de682d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b8fc537a4c44f2692696744a4e4d2ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d42dc566bdbc4914b639b8929ebe92f5",
              "IPY_MODEL_0294ce4f4da947b5b78f95d7dee7ee99",
              "IPY_MODEL_05b432c9a0cb453d9bafc66aa8451f5f"
            ],
            "layout": "IPY_MODEL_5c0e3d1c1d7b483cbad13b64f8fb1b9f"
          }
        },
        "d42dc566bdbc4914b639b8929ebe92f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a705ef86a1540cd9ca98d98e2ad6020",
            "placeholder": "​",
            "style": "IPY_MODEL_6b1b9fcc5135491297e300b5f03e9cbf",
            "value": "model.safetensors: 100%"
          }
        },
        "0294ce4f4da947b5b78f95d7dee7ee99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65b8a7e5df744570a23ee4d762868e3d",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c342335acc440389389d70e96469910",
            "value": 440449768
          }
        },
        "05b432c9a0cb453d9bafc66aa8451f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_064b8181d63544be81df54f794da208f",
            "placeholder": "​",
            "style": "IPY_MODEL_8a163c0913ef412c8206673843601df7",
            "value": " 440M/440M [00:02&lt;00:00, 145MB/s]"
          }
        },
        "5c0e3d1c1d7b483cbad13b64f8fb1b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a705ef86a1540cd9ca98d98e2ad6020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1b9fcc5135491297e300b5f03e9cbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65b8a7e5df744570a23ee4d762868e3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c342335acc440389389d70e96469910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "064b8181d63544be81df54f794da208f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a163c0913ef412c8206673843601df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7003a09e5eb4b7d9edb2eea5a156b5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5640781d59f34de58a6c5899fbecbeca",
              "IPY_MODEL_2e23a022ac154187a8f6deb63e11ce11",
              "IPY_MODEL_b12ef888798f4a42bc3305cbddbba44d"
            ],
            "layout": "IPY_MODEL_bd91c7ea94d14ede8fabaf7666e7948a"
          }
        },
        "5640781d59f34de58a6c5899fbecbeca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46e80bd2cf924d4e892505156e093fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_179a2be90ec8422a81df6c4d87d60584",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "2e23a022ac154187a8f6deb63e11ce11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80bf365a2f074d7698fe11a7c81a2143",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02173afe60184c918b37e090bb1add5e",
            "value": 48
          }
        },
        "b12ef888798f4a42bc3305cbddbba44d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e7ba33a53ad499b923f8636bd52e0c4",
            "placeholder": "​",
            "style": "IPY_MODEL_68c274c0ee2144f4b5ee75ecda5e9515",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.93kB/s]"
          }
        },
        "bd91c7ea94d14ede8fabaf7666e7948a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46e80bd2cf924d4e892505156e093fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "179a2be90ec8422a81df6c4d87d60584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80bf365a2f074d7698fe11a7c81a2143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02173afe60184c918b37e090bb1add5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e7ba33a53ad499b923f8636bd52e0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68c274c0ee2144f4b5ee75ecda5e9515": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fee1319b28354cf09ac6d94906721bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28cf37002ade428585ecfff7031aca8a",
              "IPY_MODEL_7a868c4748294773895d10d56a57ccb4",
              "IPY_MODEL_536b5ade42544898a174824d6d378222"
            ],
            "layout": "IPY_MODEL_cb196ed9ca3240199a2dadfa579cf08b"
          }
        },
        "28cf37002ade428585ecfff7031aca8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_794017e6be424936ad1119b92d483dae",
            "placeholder": "​",
            "style": "IPY_MODEL_e906c27f7b2d4f3884f4f5b0cce5addd",
            "value": "vocab.txt: 100%"
          }
        },
        "7a868c4748294773895d10d56a57ccb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_520b2d0df4b540ffae1f4dcbf08aef5f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ff4b442b4f94ce2855095f2a351a0b6",
            "value": 231508
          }
        },
        "536b5ade42544898a174824d6d378222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6d8cdd0ce9484bbc9f1ebf09297639",
            "placeholder": "​",
            "style": "IPY_MODEL_c227affac05944a4b1d26875cbab41bd",
            "value": " 232k/232k [00:00&lt;00:00, 11.3MB/s]"
          }
        },
        "cb196ed9ca3240199a2dadfa579cf08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "794017e6be424936ad1119b92d483dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e906c27f7b2d4f3884f4f5b0cce5addd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "520b2d0df4b540ffae1f4dcbf08aef5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff4b442b4f94ce2855095f2a351a0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c6d8cdd0ce9484bbc9f1ebf09297639": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c227affac05944a4b1d26875cbab41bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a94633263e5e4ca9ae24457216470c48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c7f8a34318a4c2497e5263a91d0a230",
              "IPY_MODEL_283c2ee623fc452b9a607242ae6a0a1c",
              "IPY_MODEL_ff8b9be3ab734d609f7385f72b12de74"
            ],
            "layout": "IPY_MODEL_395d9fb859ab446483328acf73cc0efb"
          }
        },
        "0c7f8a34318a4c2497e5263a91d0a230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0ce0d7042624e0992d777eab9f6b488",
            "placeholder": "​",
            "style": "IPY_MODEL_4d224bb73c0c4cc6a143f0180183aaf2",
            "value": "tokenizer.json: 100%"
          }
        },
        "283c2ee623fc452b9a607242ae6a0a1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba888dc536541839c6e48e532603b3c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7be4ae79b5f4ad89f1cbd47bbb8c46e",
            "value": 466062
          }
        },
        "ff8b9be3ab734d609f7385f72b12de74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a31ed77956734e59bee3be45121855c8",
            "placeholder": "​",
            "style": "IPY_MODEL_e9ec51fa7afa4fbbbe17c975c777c465",
            "value": " 466k/466k [00:00&lt;00:00, 11.1MB/s]"
          }
        },
        "395d9fb859ab446483328acf73cc0efb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ce0d7042624e0992d777eab9f6b488": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d224bb73c0c4cc6a143f0180183aaf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ba888dc536541839c6e48e532603b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7be4ae79b5f4ad89f1cbd47bbb8c46e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a31ed77956734e59bee3be45121855c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ec51fa7afa4fbbbe17c975c777c465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nk28-byte/MY-ASSIGNMENT/blob/main/NLP_Libraries_and_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Theoritical Questions"
      ],
      "metadata": {
        "id": "POZhWZgOFaxY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.1 What is NLTK?\n",
        "\n",
        "Ans :- NLTK, or Natural Language Toolkit, is a powerful open-source Python library widely used for Natural Language Processing (NLP) tasks. It provides tools and resources for working with human language data, making it easier to analyze, manipulate, and process text in various ways.\n",
        "\n",
        "Key Features of NLTK\n",
        "Text Preprocessing:\n",
        "\n",
        "Tokenization (breaking text into words or sentences).\n",
        "Stemming and Lemmatization (reducing words to their base/root forms).\n",
        "Stopword removal (removing common words like \"the,\" \"is,\" etc.).\n",
        "Corpus Access:\n",
        "\n",
        "Access to preloaded text corpora like Gutenberg, Brown, and WordNet for language analysis.\n",
        "Examples: Books, dictionaries, and tagged datasets.\n",
        "Text Classification:\n",
        "\n",
        "Tools for building and training machine learning models for text classification tasks like spam detection or sentiment analysis.\n",
        "Parsing and Chunking:\n",
        "\n",
        "Syntax analysis of text, such as part-of-speech tagging and parsing sentences.\n",
        "Linguistic Analysis:\n",
        "\n",
        "Tools for morphological, syntactic, and semantic analysis.\n",
        "Visualization:\n",
        "\n",
        "Visualizing data like frequency distributions or parse trees.\n",
        "Easy Integration:\n",
        "\n",
        "Works well with other Python libraries like NumPy, pandas, and scikit-learn for more complex NLP workflows.\n",
        "\n",
        "\n",
        "Q.2 What is SpaCy and how does it differ from NLTK?\n",
        "\n",
        "Ans :- SpaCy is another popular open-source library for Natural Language Processing (NLP) in Python. Like NLTK, it is used for processing and analyzing textual data, but it is designed to handle production-grade NLP tasks efficiently and at scale.\n",
        "\n",
        "Key Features of SpaCy\n",
        "Pretrained Models:\n",
        "\n",
        "SpaCy provides pretrained models for multiple languages, which are optimized for tasks like tokenization, part-of-speech (POS) tagging, named entity recognition (NER), and dependency parsing.\n",
        "Efficient and Fast:\n",
        "\n",
        "SpaCy is highly optimized for speed and performance, making it suitable for large-scale NLP tasks and real-time applications.\n",
        "Ease of Use:\n",
        "\n",
        "SpaCy offers a clean and intuitive API for developers, making it easier to use for modern NLP workflows.\n",
        "Tokenization:\n",
        "\n",
        "SpaCy uses robust tokenization that respects linguistic rules, handling things like punctuation, abbreviations, and special cases effectively.\n",
        "Integration with Deep Learning:\n",
        "\n",
        "Seamlessly integrates with popular machine learning libraries like PyTorch and TensorFlow for custom NLP models.\n",
        "Linguistic Features:\n",
        "\n",
        "Supports lemmatization, dependency parsing, named entity recognition (NER), and custom pipelines.\n",
        "Visualization:\n",
        "\n",
        "Tools like displacy allow you to visualize parse trees, entities, and other linguistic annotations directly in your browser or application\n",
        "\n",
        "\n",
        "Q.3 What is the purpose of TextBlob in NLP?\n",
        "\n",
        "Ans :- TextBlob is a Python library for Natural Language Processing (NLP) that provides a simple and intuitive interface for common text-processing tasks. It is built on top of libraries like NLTK and Pattern, making it easier to perform NLP operations without diving deep into the complexities of the underlying tools.\n",
        "\n",
        "Purpose of TextBlob in NLP\n",
        "TextBlob is designed to simplify NLP tasks, especially for beginners, by providing a high-level API for the most commonly used text-processing functions.\n",
        "\n",
        "Key Features and Applications of TextBlob\n",
        "Text Preprocessing:\n",
        "\n",
        "Tokenization: Splits text into words or sentences.\n",
        "Lemmatization: Converts words to their base form.\n",
        "Part-of-Speech Tagging: Identifies grammatical roles of words.\n",
        "Sentiment Analysis:\n",
        "\n",
        "Determines the sentiment (positive, negative, or neutral) of text.\n",
        "Provides polarity (degree of positivity/negativity) and subjectivity scores.\n",
        "Text Classification:\n",
        "\n",
        "Helps classify text using custom classifiers.\n",
        "Built-in tools for training classifiers on labeled data.\n",
        "Language Translation:\n",
        "\n",
        "Translates text between languages using Google Translate API (if enabled).\n",
        "Spelling Correction:\n",
        "\n",
        "Detects and suggests corrections for spelling errors.\n",
        "N-Grams:\n",
        "\n",
        "Extracts n-grams (sequences of n words) for analysis.\n",
        "Word and Phrase Extraction:\n",
        "\n",
        "Extracts noun phrases and keywords from text.\n",
        "Word Inflection:\n",
        "\n",
        "Converts words between singular and plural forms.\n",
        "\n",
        "\n",
        "Q.4 What is Stanford NLP?\n",
        "\n",
        "Ans :- Stanford NLP (Stanford Natural Language Processing Group) refers to a suite of Natural Language Processing (NLP) tools developed by the Stanford NLP Group, one of the leading research groups in the field of computational linguistics. It provides a range of robust, high-quality tools for analyzing and processing human language.\n",
        "\n",
        "The most well-known product from Stanford NLP is the Stanford CoreNLP, a software toolkit written in Java. It offers state-of-the-art models for a variety of NLP tasks and supports multiple languages.\n",
        "\n",
        "Key Features of Stanford NLP\n",
        "Comprehensive NLP Toolkit:\n",
        "\n",
        "Provides a complete pipeline for processing text, from tokenization to semantic analysis.\n",
        "Pretrained Models:\n",
        "\n",
        "Offers pretrained models for tasks such as part-of-speech (POS) tagging, named entity recognition (NER), and dependency parsing.\n",
        "Multilingual Support:\n",
        "\n",
        "Supports multiple languages like English, Arabic, Chinese, French, German, and Spanish.\n",
        "High Accuracy:\n",
        "\n",
        "Known for its accuracy and performance in tasks such as syntactic parsing and sentiment analysis.\n",
        "Deep Learning Integration:\n",
        "\n",
        "Uses deep learning models for tasks like NER and dependency parsing for higher precision.\n",
        "\n",
        "\n",
        "Q.5 Explain what Recurrent Neural Networks (RNN) are?\n",
        "\n",
        "Ans :- Recurrent Neural Networks (RNNs) are a type of artificial neural network designed specifically for sequential or time-series data. They are widely used in tasks where the order or sequence of the data is important, such as natural language processing, speech recognition, and time-series prediction.\n",
        "\n",
        "How RNNs Work\n",
        "Unlike traditional feedforward neural networks, RNNs have connections that form loops, enabling them to maintain a \"memory\" of previous inputs. This allows them to capture patterns over sequences.\n",
        "\n",
        "Key Characteristics:\n",
        "Sequential Processing:\n",
        "\n",
        "Inputs are processed one at a time in a sequence, and the output at each step depends on both the current input and the previous states.\n",
        "Hidden State:\n",
        "\n",
        "RNNs maintain a hidden state vector that carries information about the sequence up to the current time step.\n",
        "Shared Weights:\n",
        "\n",
        "The same weights are applied at every time step, which makes RNNs efficient and suitable for variable-length sequences.\n",
        "\n",
        "\n",
        "Q.6 What is the main advantage of using LSTM over RNN?\n",
        "\n",
        "Ans :- The main advantage of using LSTM (Long Short-Term Memory) over a standard RNN lies in its ability to effectively handle long-term dependencies in sequential data. Standard RNNs struggle with these dependencies due to the vanishing gradient problem, where gradients diminish during backpropagation, making it difficult to learn patterns from earlier time steps in long sequences.\n",
        "\n",
        "Key Advantages of LSTM Over RNN\n",
        "Better Memory Management:\n",
        "\n",
        "LSTMs introduce a sophisticated memory cell mechanism that can store and retrieve information over long periods.\n",
        "They use gates (input, forget, and output gates) to control the flow of information, deciding what to keep, update, or discard.\n",
        "Mitigation of the Vanishing Gradient Problem:\n",
        "\n",
        "By preserving gradients more effectively, LSTMs enable the learning of dependencies over long sequences, which standard RNNs struggle with.\n",
        "Capturing Long-Term Dependencies:\n",
        "\n",
        "LSTMs excel in tasks where the output at a particular time step depends on inputs from much earlier in the sequence.\n",
        "Flexibility with Sequence Lengths:\n",
        "\n",
        "LSTMs are well-suited for variable-length sequences, making them useful in tasks like language translation, speech recognition, and time-series prediction.\n",
        "\n",
        "Q.7 What are Bi-directional LSTMs, and how do they differ from standard LSTMs?\n",
        "\n",
        "Ans :- Bi-directional LSTMs (BiLSTMs) are an advanced variant of the standard Long Short-Term Memory (LSTM) networks. They differ from standard LSTMs in their ability to process input sequences in both forward and backward directions, providing a more comprehensive understanding of the context.\n",
        "\n",
        "Key Characteristics of BiLSTMs\n",
        "Bidirectional Processing:\n",
        "\n",
        "Standard LSTMs process data sequentially in a forward direction, from the start to the end of the sequence.\n",
        "BiLSTMs add another LSTM layer that processes the sequence in reverse, from the end to the start.\n",
        "Combining Context:\n",
        "\n",
        "By analyzing the sequence in both directions, BiLSTMs can capture past (left) and future (right) context, resulting in better performance for tasks requiring a deeper understanding of the sequence.\n",
        "Architecture:\n",
        "\n",
        "A BiLSTM has two hidden states at each time step: one from the forward pass and one from the backward pass.\n",
        "These states are concatenated or combined (e.g., summed or averaged) before being passed to the next layer.\n",
        "\n",
        "\n",
        "Q.8 What is the purpose of a Stacked LSTM?\n",
        "\n",
        "Ans :- Stacked LSTM is a neural network architecture where multiple LSTM layers are stacked on top of each other, creating a deep model. The purpose of stacking LSTM layers is to enable the network to learn more complex patterns and hierarchical representations in sequential data. This deeper structure allows the model to capture both low-level and high-level features, making it particularly effective for tasks involving long-term dependencies and complex sequences.\n",
        "\n",
        "Key Features of Stacked LSTMs\n",
        "Hierarchical Feature Learning:\n",
        "\n",
        "The first LSTM layer processes the input sequence and extracts basic features.\n",
        "Subsequent LSTM layers process the outputs of the previous layer, capturing more abstract, higher-level patterns.\n",
        "Improved Representational Power:\n",
        "\n",
        "With multiple layers, the model can learn intricate relationships and dependencies that a single-layer LSTM might miss.\n",
        "Capturing Long and Short-Term Dependencies:\n",
        "\n",
        "Deeper LSTMs can capture both short-term patterns in early layers and long-term dependencies in later layers.\n",
        "\n",
        "\n",
        "Q.9 How does a GRU (Gated Recurrent Unit) differ from an LSTM?\n",
        "\n",
        "Ans :- A GRU (Gated Recurrent Unit) and an LSTM (Long Short-Term Memory) are both advanced types of recurrent neural networks (RNNs) designed to solve the vanishing gradient problem and handle long-term dependencies in sequential data. However, they differ in their architectures, complexity, and performance characteristics.\n",
        "\n",
        "Key Differences Between GRU and LSTM\n",
        "Aspect\tLSTM\tGRU\n",
        "Number of Gates\t3 gates: Input gate, Forget gate, Output gate.\t2 gates: Update gate, Reset gate.\n",
        "Memory Cells\tHas a separate memory cell (\n",
        "𝐶\n",
        "𝑡\n",
        "C\n",
        "t\n",
        "​\n",
        " ) and hidden state (\n",
        "ℎ\n",
        "𝑡\n",
        "h\n",
        "t\n",
        "​\n",
        " ).\tCombines memory and hidden state into a single state.\n",
        "Complexity\tMore parameters due to additional gates and memory cell.\tSimpler architecture, fewer parameters.\n",
        "Training Speed\tSlower training due to greater complexity.\tFaster training because of simpler computations.\n",
        "Flexibility\tBetter at handling very long sequences due to explicit memory cells.\tPerforms well for moderate-length sequences.\n",
        "Performance on Small Data\tMay overfit on small datasets due to complexity.\tOften generalizes better on smaller datasets.\n",
        "Use Cases\tOften preferred for tasks requiring long-term memory.\tUseful for tasks requiring faster training and efficiency.\n",
        "\n",
        "\n",
        "Q.10  What are the key features of NLTK's tokenization process?\n",
        "\n",
        "Ans :- NLTK (Natural Language Toolkit) provides a robust and versatile tokenization process, which is a key step in natural language processing (NLP). Tokenization involves breaking down a text into smaller units, such as sentences or words, enabling further analysis like part-of-speech tagging, parsing, or text classification. Below are the key features of NLTK's tokenization process:\n",
        "\n",
        "Key Features of NLTK's Tokenization Process\n",
        "1. Versatility:\n",
        "NLTK supports word tokenization and sentence tokenization, making it adaptable for various tasks:\n",
        "Word Tokenization: Breaks text into individual words.\n",
        "Sentence Tokenization: Splits text into sentences.\n",
        "2. Predefined Tokenizers:\n",
        "NLTK provides several built-in tokenizers optimized for different use cases:\n",
        "Word Tokenizer: Breaks text into words, considering punctuation.\n",
        "Punkt Sentence Tokenizer: Uses a pre-trained unsupervised model to split text into sentences.\n",
        "RegexpTokenizer: Allows users to define custom tokenization rules using regular expressions.\n",
        "WhitespaceTokenizer: Splits text based on whitespace only.\n",
        "TweetTokenizer: Specialized for tokenizing social media content like tweets, handling hashtags, mentions, and emojis.\n",
        "3. Language Support:\n",
        "The Punkt Tokenizer in NLTK supports multiple languages (e.g., English, French, German) by using language-specific models for sentence tokenization.\n",
        "4. Handling of Complex Structures:\n",
        "NLTK tokenizers handle complex text structures like:\n",
        "Abbreviations (e.g., \"Dr.\", \"etc.\")\n",
        "Dates and numbers\n",
        "Proper handling of punctuation and contractions (e.g., \"don't\", \"I'm\").\n",
        "\n",
        "\n",
        "Q.11 How do you perform named entity recognition (NER) using SpaCy?\n",
        "\n",
        "Ans :- Named Entity Recognition (NER) is a key task in Natural Language Processing (NLP) that involves identifying and classifying named entities (such as person names, organizations, dates, locations, etc.) within a text. SpaCy provides an easy-to-use and efficient way to perform NER.\n",
        "\n",
        "Here's a step-by-step guide to performing NER using SpaCy:\n",
        "\n",
        "1. Install SpaCy\n",
        "If you haven't already installed SpaCy, you can do so via pip:\n",
        "\n",
        "bash\n",
        "Copy code\n",
        "pip install spacy\n",
        "2. Download a Pre-trained SpaCy Model\n",
        "SpaCy provides pre-trained models for different languages. For English, you can download the small English model (en_core_web_sm) or the larger models for better accuracy.\n",
        "\n",
        "To install the English model:\n",
        "\n",
        "bash\n",
        "Copy code\n",
        "python -m spacy download en_core_web_sm\n",
        "You can also use the larger models like en_core_web_md or en_core_web_lg for better accuracy.\n",
        "\n",
        "\n",
        "Q.12 What is Word2Vec and how does it represent words?\n",
        "\n",
        "Ans :- Word2Vec (Word to Vector) is a popular word embedding model used in Natural Language Processing (NLP) to represent words as dense vectors (i.e., arrays of real numbers). Word2Vec is a type of unsupervised learning algorithm that learns the vector representation of words from a large corpus of text by capturing semantic relationships between words.\n",
        "\n",
        "Key Concepts in Word2Vec\n",
        "Word Embeddings:\n",
        "\n",
        "Word2Vec transforms words into continuous dense vectors of fixed length (e.g., 100, 200, or 300 dimensions), where each dimension captures some aspect of the word's meaning.\n",
        "These vectors are often compared to one-hot encoding, but Word2Vec vectors are more compact and provide richer semantic information.\n",
        "Training Objective:\n",
        "\n",
        "Word2Vec is trained using a large text corpus to learn vector representations for words that reflect their semantic meaning based on their context in the text.\n",
        "The key idea is that words with similar meanings should be represented by similar vectors, and these relationships are captured based on word context (i.e., co-occurrence in the text).\n",
        "Context and Proximity:\n",
        "\n",
        "Words that appear in similar contexts (i.e., they share common neighbors or appear in similar environments in sentences) are represented by similar vectors.\n",
        "For example, \"king\" and \"queen\" will have similar vector representations because they often appear in similar contexts (e.g., in sentences involving royalty).\n",
        "\n",
        "\n",
        "Q.13 Explain the difference between Bag of Words (BoW) and Word2VecK?\n",
        "\n",
        "Ans :- The Bag of Words (BoW) and Word2Vec models are both used to represent text in a numerical form that can be processed by machine learning algorithms, but they differ significantly in their approach, capabilities, and the type of information they capture.\n",
        "\n",
        "Here's a detailed comparison between Bag of Words (BoW) and Word2Vec:\n",
        "\n",
        "1. Representation of Words\n",
        "Bag of Words (BoW):\n",
        "\n",
        "BoW represents text by counting the frequency of each word in the document or corpus, ignoring grammar and word order.\n",
        "The representation is a sparse vector (high-dimensional) where each dimension corresponds to a word in the vocabulary. The value in that dimension represents the frequency of the word in the text.\n",
        "Example:\n",
        "\n",
        "Text 1: \"I love programming.\"\n",
        "Text 2: \"I enjoy programming.\"\n",
        "If the vocabulary is [\"I\", \"love\", \"programming\", \"enjoy\"], the BoW vectors for the two sentences will be:\n",
        "\n",
        "Text 1: [1, 1, 1, 0] (1 occurrence of each word)\n",
        "Text 2: [1, 0, 1, 1] (1 occurrence of each word)\n",
        "This results in sparse vectors where the vector size equals the size of the vocabulary.\n",
        "\n",
        "Word2Vec:\n",
        "\n",
        "Word2Vec represents each word as a dense vector of real numbers (low-dimensional), where words with similar meanings are represented by similar vectors.\n",
        "The model is trained using large text corpora and captures semantic relationships between words based on their context.\n",
        "Word2Vec vectors are continuous and not discrete, and they are generated by training the model on word co-occurrence patterns (using CBOW or Skip-gram models).\n",
        "\n",
        "\n",
        "Q.14 How does TextBlob handle sentiment analysis?\n",
        "\n",
        "Ans :- TextBlob is a simple and easy-to-use Python library for Natural Language Processing (NLP), which includes functionality for performing sentiment analysis. It uses a pre-trained model and a lexicon-based approach to assess the sentiment of a given text, classifying it as positive, negative, or neutral. Here’s a breakdown of how TextBlob handles sentiment analysis:\n",
        "\n",
        "TextBlob Sentiment Analysis Overview\n",
        "TextBlob Sentiment API:\n",
        "TextBlob provides a sentiment property for text objects, which returns two values:\n",
        "Polarity: A float that ranges from -1 to 1. It indicates the sentiment's polarity:\n",
        "-1 means the text is most negative.\n",
        "1 means the text is most positive.\n",
        "0 means the text has neutral sentiment.\n",
        "Subjectivity: A float that ranges from 0 to 1. It indicates the degree of subjectivity:\n",
        "0 means the text is objective (factual).\n",
        "1 means the text is subjective (opinion-based).\n",
        "\n",
        "\n",
        "Q.15  How would you implement text preprocessing using NLTK?\n",
        "\n",
        "Ans :- Implementing text preprocessing using NLTK (Natural Language Toolkit) involves several common tasks that are essential to clean and prepare text data for downstream NLP tasks. These tasks include:\n",
        "\n",
        "Tokenization: Splitting text into words or sentences.\n",
        "Lowercasing: Converting all text to lowercase.\n",
        "Removing punctuation and stop words: Removing non-informative words like articles, prepositions, and punctuation marks.\n",
        "Stemming: Reducing words to their root form.\n",
        "Lemmatization: Reducing words to their base or dictionary form.\n",
        "Removing special characters or digits: Cleaning the text of any unwanted characters.\n",
        "Whitespace handling: Removing excess whitespace.\n",
        "\n",
        "Q.16 K How do you train a custom NER model using SpaCy?\n",
        "\n",
        "Ans :- Training a custom Named Entity Recognition (NER) model using SpaCy involves several steps. Here’s a complete guide on how to go from data collection to training a model for NER.\n",
        "\n",
        "Q.17  What is the role of the attention mechanism in LSTMs and GRUs?\n",
        "\n",
        "Ans :- The attention mechanism plays a critical role in enhancing the performance of Recurrent Neural Networks (RNNs), especially in models like LSTMs (Long Short-Term Memory) and GRUs (Gated Recurrent Units), which are typically used in sequence-to-sequence tasks such as machine translation, text summarization, and speech recognition.\n",
        "\n",
        "Understanding the Challenge\n",
        "In traditional RNNs, including LSTMs and GRUs, the model processes the input sequence one element at a time. As the sequence length increases, the model might struggle to retain long-term dependencies due to the vanishing gradient problem (although LSTMs and GRUs help mitigate this issue).\n",
        "\n",
        "Even though LSTMs and GRUs are designed to capture long-term dependencies, they still face challenges in focusing on specific parts of the input sequence when generating each output. This is particularly problematic in tasks like machine translation, where not every word in the input sequence contributes equally to every word in the output sequence.\n",
        "\n",
        "Role of the Attention Mechanism\n",
        "The attention mechanism addresses this issue by allowing the model to dynamically focus on different parts of the input sequence when generating each output token. Instead of processing the entire sequence in a single pass, the attention mechanism computes a weighted sum of the hidden states from all time steps of the input sequence and assigns higher weights to more relevant parts of the sequence for each output step.\n",
        "\n",
        "In simpler terms, attention allows the model to \"attend\" to the most important parts of the input sequence while making predictions. This allows the model to capture long-range dependencies more effectively and improves performance in tasks requiring alignment between input and output sequences.\n",
        "\n",
        "\n",
        "Q.18 What is the difference between tokenization and lemmatization in NLP?\n",
        "\n",
        "Ans :- In Natural Language Processing (NLP), tokenization and lemmatization are two fundamental text preprocessing techniques, but they serve different purposes and operate at different stages of text analysis. Here's a detailed breakdown of the differences between the two:\n",
        "\n",
        "1. Tokenization\n",
        "Definition: Tokenization is the process of breaking down a piece of text (such as a sentence or a paragraph) into smaller units called tokens. These tokens could be words, subwords, characters, or sentences, depending on the level of tokenization.\n",
        "\n",
        "Purpose: The primary purpose of tokenization is to divide text into manageable chunks for further analysis, such as part-of-speech tagging, named entity recognition (NER), and machine learning tasks.\n",
        "\n",
        "\n",
        "Q.19 How do you perform text normalization in NLP?\n",
        "\n",
        "Ans :- Text normalization is an essential step in Natural Language Processing (NLP) that involves converting raw text into a more standardized format. This process helps improve the quality of text data and ensures consistency, which is especially important for text analysis, machine learning models, and downstream NLP tasks. The goal is to transform the text into a form that is easier to process and analyze.\n",
        "\n",
        "Steps in Text Normalization\n",
        "Text normalization typically involves several key operations, depending on the task. Below are some common techniques:\n",
        "\n",
        "\n",
        "Q.20 What is the purpose of frequency distribution in NLP?\n",
        "\n",
        "Ans :- In Natural Language Processing (NLP), frequency distribution is a useful tool that helps analyze and understand the distribution of words or tokens within a given corpus or dataset. It refers to the process of counting how often each word (or token) appears in the text, providing insights into the text's structure, vocabulary, and patterns.\n",
        "\n",
        "Purpose of Frequency Distribution in NLP\n",
        "Understanding Word Importance and Context\n",
        "\n",
        "By analyzing the frequency distribution of words in a text, we can identify which words are most commonly used. This helps in understanding the theme, tone, or main topics of the text. Words that appear more frequently might be central to the content and meaning.\n",
        "For instance, in a news article, frequently occurring words like \"economy,\" \"government,\" or \"market\" could indicate the main topics of discussion.\n",
        "Feature Engineering for NLP Models\n",
        "\n",
        "Frequency distributions are often used in feature engineering for machine learning models. The frequency of words (often referred to as the term frequency) is one of the key features used in text classification tasks, such as sentiment analysis, spam detection, and topic modeling.\n",
        "For example, bag of words models rely on the frequency of words as features to classify text into categories.\n",
        "Text Preprocessing and Filtering\n",
        "\n",
        "Stop words (common words like \"the,\" \"is,\" \"and\") can be identified and removed by looking at the frequency distribution, as they often occur very frequently and do not carry much meaning for specific tasks.\n",
        "Words that occur too rarely can also be filtered out, as they might not provide enough information or could introduce noise in the analysis.\n",
        "Identifying Key Terms and Topics\n",
        "\n",
        "Frequency distribution helps in identifying key terms, keywords, or n-grams that are most representative of a document or corpus. In tasks like topic modeling or document clustering, the frequency of certain terms can help group related documents or identify the primary subjects of a text.\n",
        "Text Summarization\n",
        "\n",
        "In extractive text summarization, the most frequent words (or phrases) in a document or a set of documents can be used to identify important sentences for the summary. Frequent terms can indicate the significance of the corresponding sentences.\n",
        "\n",
        "\n",
        "Q.21 What are co-occurrence vectors in NLP?\n",
        "\n",
        "Ans :- n Natural Language Processing (NLP), co-occurrence vectors are used to represent the relationships between words based on the context in which they appear together within a corpus. These vectors capture how often two words appear together within a certain context window (e.g., within a sentence, a fixed number of words, or a defined text span). The idea is that words that frequently occur together in similar contexts are likely to have similar meanings or be related in some way.\n",
        "\n",
        "Co-occurrence Vectors Explained\n",
        "A co-occurrence vector is essentially a mathematical representation of a word's relationship with other words in the text, where each dimension of the vector corresponds to the frequency with which the word appears in the same context as another word.\n",
        "\n",
        "Context Window: In most co-occurrence models, a context window is defined. The context window refers to the number of words around a target word that are considered as part of its context. For example:\n",
        "A window size of 1 means that only the word immediately preceding and following the target word are considered as its context.\n",
        "A window size of 2 means that the two preceding and two following words are considered as context.\n",
        "Co-occurrence Matrix: A co-occurrence matrix is a matrix where rows and columns represent words in the corpus. Each entry in the matrix indicates the number of times the word corresponding to the row appears in the context of the word corresponding to the column, based on the defined context window.\n",
        "\n",
        "\n",
        "Q.22 How is Word2Vec used to find the relationship between words?\n",
        "\n",
        "Ans :- Word2Vec is a popular word embedding technique that is used to represent words as dense, continuous vectors in a high-dimensional space. It is trained using large text corpora and captures semantic relationships between words based on the context in which they appear. Word2Vec allows us to model the relationships between words in a way that is highly efficient and computationally manageable, unlike traditional methods like co-occurrence matrices.\n",
        "\n",
        "How Word2Vec Works\n",
        "Word2Vec uses two main architectures to learn word vectors:\n",
        "\n",
        "Continuous Bag of Words (CBOW):\n",
        "This model predicts a target word based on its surrounding context words.\n",
        "For example, in the sentence “The cat sat on the mat,” the context words around \"sat\" (e.g., \"The\", \"cat\", \"on\", \"the\", \"mat\") are used to predict the target word \"sat\".\n",
        "Skip-gram:\n",
        "This model works in reverse: it predicts the surrounding context words based on a target word.\n",
        "For example, given the target word \"sat,\" the model tries to predict context words like \"The\", \"cat\", \"on\", \"the\", \"mat\".\n",
        "\n",
        "\n",
        "Q.23 How does a Bi-LSTM improve NLP tasks compared to a regular LSTM?\n",
        "\n",
        "Ans :- A Bi-LSTM (Bidirectional Long Short-Term Memory) is an extension of the traditional LSTM (Long Short-Term Memory) model, designed to improve performance on certain NLP tasks by providing more context to each decision. The key difference lies in the way a Bi-LSTM processes sequences: it uses two LSTM layers, one processing the sequence in the forward direction (from left to right) and the other in the reverse direction (from right to left).\n",
        "\n",
        "How Bi-LSTM Improves NLP Tasks Compared to Regular LSTM\n",
        "Captures Both Forward and Backward Context:\n",
        "\n",
        "LSTM: A standard LSTM processes the input sequence from left to right (or right to left, depending on the configuration). This means the model has access to the past context of a sequence but doesn't have direct access to future context during training and prediction.\n",
        "\n",
        "Bi-LSTM: A Bi-LSTM processes the input sequence in two directions: forward (left to right) and backward (right to left). This means the model can learn both past and future context, providing a richer representation of the sequence. This is particularly useful for tasks where understanding both the previous and subsequent elements of a sequence is important for accurate predictions.\n",
        "\n",
        "\n",
        "Q.24 What is the difference between a GRU and an LSTM in terms of gate structures?\n",
        "\n",
        "Ans :- The GRU (Gated Recurrent Unit) and LSTM (Long Short-Term Memory) are both types of recurrent neural networks (RNNs) designed to address the vanishing gradient problem and improve long-range dependency learning. While both models are designed to manage the flow of information in sequences, they differ in terms of gate structures and the number of gates they use.\n",
        "\n",
        "Key Differences in Gate Structures:\n",
        "1. LSTM Gate Structure:\n",
        "An LSTM has three primary gates that control the flow of information:\n",
        "\n",
        "Forget Gate: Decides what proportion of the previous memory should be discarded.\n",
        "Input Gate: Determines which values from the current input should be added to the cell state.\n",
        "Output Gate: Controls which values from the cell state should be output to the next layer in the sequence.\n",
        "Additionally, an LSTM has a cell state, which is a memory unit that carries long-term dependencies and helps to preserve important information over time. The cell state is modified by the forget and input gates\n",
        "\n",
        "\n",
        "Q.25  How does Stanford NLP’s dependency parsing work?\n",
        "\n",
        "Ans :- Stanford NLP's Dependency Parsing is a process of analyzing the grammatical structure of a sentence, focusing on the relationships between words. In dependency parsing, each word in a sentence is connected to another word (called its \"head\") in a way that reflects the syntactic dependencies between them. The goal is to produce a dependency tree that shows how each word depends on others.\n",
        "\n",
        "How Stanford NLP's Dependency Parsing Works\n",
        "Stanford's Dependency Parser is based on machine learning models and uses a graph-based approach to produce the dependency tree. Here's a step-by-step breakdown of how it works:\n",
        "\n",
        "Input Sentence:\n",
        "\n",
        "The first step is to take an input sentence. For example:\n",
        "\"The quick brown fox jumps over the lazy dog.\"\n",
        "Tokenization:\n",
        "\n",
        "The sentence is first tokenized into individual words or subwords (tokens). Tokenization is a process where the sentence is split into its basic components (such as words, punctuation marks, etc.).\n",
        "Tokens: [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\"]\n",
        "\n",
        "\n",
        "Q.26 K How does tokenization affect downstream NLP tasks?\n",
        "\n",
        "Ans :- Tokenization is the first step in many NLP (Natural Language Processing) pipelines, where text is split into smaller units like words, subwords, or characters. The way tokenization is performed can have a significant impact on downstream tasks, such as sentiment analysis, named entity recognition (NER), machine translation, or text classification. Here's how tokenization can affect various downstream NLP tasks:\n",
        "\n",
        "1. Word-Level Tokenization\n",
        "In word-level tokenization, text is split into individual words. This is the most common approach for tasks like sentiment analysis and text classification.\n",
        "\n",
        "Impact:\n",
        "Accuracy: Word-level tokenization works well for languages like English, where words are generally clear-cut. However, in languages with compounds or agglutinative structures (like German or Turkish), word-level tokenization may break words into too many pieces, leading to less meaningful representations.\n",
        "Handling of Punctuation: Punctuation marks are typically treated as separate tokens. In some cases, this might be useful, but in others, punctuation might need to be merged with words (e.g., in sentiment analysis, \"not good\" vs. \"not, good\").\n",
        "\n",
        "\n",
        "Q.27 What are some common applications of NLP?\n",
        "\n",
        "Ans :- Natural Language Processing (NLP) has a wide range of applications across various fields. Here are some of the most common and impactful applications of NLP:\n",
        "\n",
        "1. Sentiment Analysis\n",
        "Purpose: To determine the sentiment or emotion behind a piece of text (e.g., whether a review is positive, negative, or neutral).\n",
        "Applications:\n",
        "Social media monitoring (e.g., analyzing Twitter or Facebook posts to gauge public opinion).\n",
        "Customer feedback analysis (e.g., analyzing product reviews).\n",
        "Brand monitoring (e.g., detecting potential issues by analyzing sentiments around a brand).\n",
        "2. Machine Translation\n",
        "Purpose: Automatically translating text from one language to another.\n",
        "Applications:\n",
        "Google Translate, Microsoft Translator, and other online translation tools.\n",
        "Multilingual content generation for websites, marketing, or customer support.\n",
        "Cross-lingual communication in international organizations or businesses.\n",
        "3. Named Entity Recognition (NER)\n",
        "Purpose: Identifying and classifying named entities (such as persons, locations, dates, etc.) in text.\n",
        "Applications:\n",
        "Information extraction from documents (e.g., extracting company names, dates, or other key data from resumes, articles, or research papers).\n",
        "Automated news categorization (e.g., identifying and categorizing mentions of politicians, events, or companies).\n",
        "Customer support automation (e.g., recognizing product names, locations, etc. in customer queries).\n",
        "\n",
        "\n",
        "Q.28 What are stopwords and why are they removed in NLP?\n",
        "\n",
        "Ans :- Stopwords are common words that carry very little meaningful information in the context of natural language processing (NLP) and are often removed from text data before further processing. These words typically include articles, prepositions, conjunctions, pronouns, auxiliary verbs, and other frequently occurring words that do not contribute significantly to the core meaning of a sentence.\n",
        "\n",
        "Examples of Stopwords:\n",
        "Articles: \"a\", \"an\", \"the\"\n",
        "Prepositions: \"in\", \"on\", \"at\", \"by\", \"for\"\n",
        "Conjunctions: \"and\", \"but\", \"or\", \"so\"\n",
        "Pronouns: \"he\", \"she\", \"it\", \"they\"\n",
        "Auxiliary verbs: \"is\", \"am\", \"are\", \"was\", \"were\"\n",
        "Why Stopwords Are Removed in NLP:\n",
        "Reduce Noise:\n",
        "\n",
        "Stopwords don't provide much information to models when trying to extract meaning from a text. Including them can lead to unnecessary noise in the data and reduce the effectiveness of NLP tasks like text classification, sentiment analysis, or topic modeling.\n",
        "Improve Efficiency:\n",
        "\n",
        "Removing stopwords reduces the size of the data and the vocabulary that needs to be processed. This helps reduce computational complexity and speeds up model training and prediction. By excluding these common but unimportant words, models focus on the more meaningful words in the text.\n",
        "\n",
        "\n",
        "Q.29 K How can you implement word embeddings using Word2Vec in Python?\n",
        "\n",
        "Ans :- ou can implement word embeddings using Word2Vec in Python by utilizing the Gensim library, which provides an efficient and easy-to-use implementation of Word2Vec. Here's how you can go about it:\n",
        "\n",
        "\n",
        "Q.30 How does SpaCy handle lemmatization?\n",
        "\n",
        "Ans :- SpaCy handles lemmatization by using its built-in linguistic models that are designed to recognize and reduce words to their base or dictionary form, called lemmas. Lemmatization is the process of converting a word into its base form, which can be more useful for downstream NLP tasks like text analysis or sentiment analysis.\n",
        "\n",
        "How SpaCy Handles Lemmatization:\n",
        "Linguistic Model: SpaCy uses a pre-trained language model (depending on the language you are working with, like English, German, etc.) to perform lemmatization. The model contains rules about word forms, suffixes, and exceptions in the language, allowing it to accurately identify the correct lemma.\n",
        "\n",
        "Lemmatization Process: When SpaCy processes text, it performs part-of-speech tagging and syntactic analysis. Based on the context and the part of speech of a word, SpaCy assigns the appropriate lemma for each word. For example:\n",
        "\n",
        "\n",
        "Q.31 What is the significance of RNNs in NLP tasks?\n",
        "\n",
        "Ans :- Recurrent Neural Networks (RNNs) are highly significant in Natural Language Processing (NLP) tasks because they are designed to handle sequential data, which is characteristic of language. Unlike traditional feed-forward neural networks, RNNs have the ability to maintain a memory of previous inputs, making them well-suited for tasks where the context of earlier words affects the interpretation of later words.\n",
        "\n",
        "Significance of RNNs in NLP Tasks:\n",
        "Handling Sequential Data:\n",
        "\n",
        "In NLP, language is inherently sequential: the meaning of a sentence or phrase depends on the order of words. RNNs are capable of processing sequences of words, one word at a time, and maintaining a hidden state that carries information about the previous words. This makes them ideal for tasks like language modeling, speech recognition, and text generation.\n",
        "Contextual Understanding:\n",
        "\n",
        "RNNs have the ability to capture context over time. In language, the meaning of a word can change based on the surrounding words. For example, the word \"bank\" could refer to a financial institution or the side of a river, and an RNN can use the context provided by neighboring words to interpret its meaning correctly. This is crucial in tasks like named entity recognition (NER), part-of-speech tagging, and sentiment analysis.\n",
        "\n",
        "Q.32  How does word embedding improve the performance of NLP models?\n",
        "\n",
        "Ans :- ord embeddings play a critical role in improving the performance of NLP models by transforming text data into dense numerical representations that capture the semantic meaning of words. These dense representations are more efficient and effective than traditional sparse representations (like Bag of Words or TF-IDF), allowing NLP models to understand relationships and contextual meanings between words.\n",
        "\n",
        "Here’s how word embeddings improve the performance of NLP models:\n",
        "\n",
        "1. Capturing Semantic Relationships:\n",
        "Word embeddings, such as Word2Vec, GloVe, or FastText, map words with similar meanings to nearby points in the vector space. For example, words like \"king\" and \"queen\" will have embeddings that are close to each other, and their vector difference (like \"king\" - \"man\" + \"woman\") can yield a vector close to \"queen\".\n",
        "This captures relationships between words in a way that traditional methods like Bag of Words or TF-IDF cannot, which only represent words in isolation.\n",
        "2. Reducing Sparsity:\n",
        "In Bag of Words or TF-IDF, the text is represented as a sparse vector with hundreds or thousands of dimensions, each representing a unique word in the vocabulary. This results in high-dimensional, sparse vectors, which are computationally expensive and less effective.\n",
        "Word embeddings represent each word as a dense vector in a much lower-dimensional space (e.g., 100-300 dimensions), making the data more compact, efficient to compute, and easier for models to learn from.\n",
        "3. Handling Synonymy and Polysemy:\n",
        "Synonymy: Word embeddings can capture the similarity between words with similar meanings. For instance, \"happy\" and \"joyful\" will have similar embeddings, which allows the model to understand that these words can be used interchangeably.\n",
        "Polysemy: Word embeddings can help mitigate the issue of polysemy, where a single word has multiple meanings. For example, \"bank\" as a financial institution and \"bank\" as the side of a river will have different embeddings based on their context in the sentence, helping models differentiate between meanings.\n",
        "\n",
        "\n",
        "Q.33  How does a Stacked LSTM differ from a single LSTM?\n",
        "\n",
        "Ans :- A Stacked LSTM and a single LSTM differ primarily in their architectural complexity and the depth of their network. A Stacked LSTM consists of multiple LSTM layers stacked on top of each other, while a single LSTM has only one layer. Below are the key differences and advantages of using a Stacked LSTM over a single LSTM:\n",
        "\n",
        "1. Depth of the Model:\n",
        "Single LSTM:\n",
        "A single LSTM consists of only one layer of LSTM cells, where each cell processes the sequence data one step at a time.\n",
        "It’s a simple model, suitable for relatively simple sequence tasks where the relationship between the inputs and outputs does not require multiple levels of abstraction.\n",
        "Stacked LSTM:\n",
        "A Stacked LSTM has multiple layers of LSTM cells stacked on top of each other. The output from one LSTM layer becomes the input to the next LSTM layer.\n",
        "This creates a deeper network that can learn more complex patterns and abstract features from the input data.\n",
        "\n",
        "\n",
        "Q.34 K What are the key differences between RNN, LSTM, and GRU?\n",
        "\n",
        "Ans :- The key differences between Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRUs) lie in their architectures and mechanisms for handling sequential data, especially when it comes to managing long-term dependencies. Here's a breakdown of the primary differences:\n",
        "\n",
        "1. Basic Structure and Gates:\n",
        "RNN:\n",
        "\n",
        "A basic RNN consists of a simple recurrent structure where the output of the previous time step is fed into the network along with the current input. However, it struggles to capture long-term dependencies due to the vanishing gradient problem.\n",
        "It has no gating mechanisms to control the flow of information, so it tends to forget earlier inputs as the sequence gets longer.\n",
        "LSTM:\n",
        "\n",
        "LSTM is a more advanced RNN architecture designed to address the vanishing gradient problem. It introduces gates to control the flow of information.\n",
        "It has three main gates:\n",
        "Forget Gate: Decides which information from the previous cell state should be discarded.\n",
        "Input Gate: Decides which new information should be stored in the cell state.\n",
        "Output Gate: Controls which information from the cell state should be output at the current time step.\n",
        "These gates help LSTMs maintain long-term dependencies and preserve information across long sequences.\n",
        "GRU:\n",
        "\n",
        "GRU is a simplified version of LSTM with fewer parameters. It combines the forget and input gates into a single update gate and uses a reset gate to control how much of the past information to forget.\n",
        "GRU has two main gates:\n",
        "Update Gate: Controls how much of the previous state to carry forward (similar to both the forget and input gates in LSTM).\n",
        "Reset Gate: Determines how much of the past state should be ignored when calculating the current state.\n",
        "5 The key differences between Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Gated Recurrent Units (GRUs) lie in their architectures and mechanisms for handling sequential data, especially when it comes to managing long-term dependencies. Here's a breakdown of the primary differences:\n",
        "\n",
        "1. Basic Structure and Gates:\n",
        "RNN:\n",
        "\n",
        "A basic RNN consists of a simple recurrent structure where the output of the previous time step is fed into the network along with the current input. However, it struggles to capture long-term dependencies due to the vanishing gradient problem.\n",
        "It has no gating mechanisms to control the flow of information, so it tends to forget earlier inputs as the sequence gets longer.\n",
        "LSTM:\n",
        "\n",
        "LSTM is a more advanced RNN architecture designed to address the vanishing gradient problem. It introduces gates to control the flow of information.\n",
        "It has three main gates:\n",
        "Forget Gate: Decides which information from the previous cell state should be discarded.\n",
        "Input Gate: Decides which new information should be stored in the cell state.\n",
        "Output Gate: Controls which information from the cell state should be output at the current time step.\n",
        "These gates help LSTMs maintain long-term dependencies and preserve information across long sequences.\n",
        "GRU:\n",
        "\n",
        "GRU is a simplified version of LSTM with fewer parameters. It combines the forget and input gates into a single update gate and uses a reset gate to control how much of the past information to forget.\n",
        "GRU has two main gates:\n",
        "Update Gate: Controls how much of the previous state to carry forward (similar to both the forget and input gates in LSTM).\n",
        "Reset Gate: Determines how much of the past state should be ignored when calculating the current state.\n",
        "\n",
        "\n",
        "Q.35 K Why is the attention mechanism important in sequence-to-sequence models?\n",
        "\n",
        "Ans :- The attention mechanism plays a crucial role in sequence-to-sequence models (like those used in machine translation, speech recognition, and text summarization) by helping the model focus on the most relevant parts of the input sequence while generating the output. Here's why it is important:\n",
        "\n",
        "1. Handling Long-Range Dependencies:\n",
        "In traditional sequence-to-sequence models (such as those using RNNs, LSTMs, or GRUs), the encoder processes the entire input sequence and compresses it into a single fixed-length context vector (often called the latent vector or thought vector). This context vector is then used by the decoder to generate the output sequence.\n",
        "However, this fixed-length context vector often struggles to capture long-range dependencies, especially when the input sequence is long. The attention mechanism overcomes this by allowing the model to focus on different parts of the input sequence at each time step while decoding, effectively mitigating the problem of forgetting distant parts of the sequence.\n",
        "2. Dynamic Focus on Relevant Information:\n",
        "The attention mechanism enables the decoder to \"attend\" to different positions of the input sequence dynamically, based on the context at each decoding step.\n",
        "At each decoding step, the model can calculate an attention weight for each word in the input sequence, indicating how much the model should focus on that particular word. This means the model can pay more attention to certain words (such as keywords or important phrases) and ignore others that are less relevant.\n",
        "This flexibility allows the model to handle tasks where the relationship between input and output is not fixed or linear (e.g., translation, where words in a sentence don't always align perfectly)."
      ],
      "metadata": {
        "id": "wk_umiOPFhuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Questions"
      ],
      "metadata": {
        "id": "5c7HQnB7FhQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "id": "XVl2IOXSFM0P",
        "outputId": "82117c5a-0def-4a13-c988-1c449206a2a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f13336fffdc5>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Tokenize the text into words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Create a frequency distribution of the words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     return [\n\u001b[1;32m    144\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_punkt_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36m_get_punkt_tokenizer\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPunktTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m         \u001b[0mPunktSentenceTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_lang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/punkt.py\u001b[0m in \u001b[0;36mload_lang\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m   1747\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1749\u001b[0;31m         \u001b[0mlang_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt_tab/{lang}/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1750\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_punkt_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lang\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt_tab\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt_tab')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt_tab/english/\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "# Q.1 How do you perform word tokenization using NLTK and plot a word frequency distribution?\n",
        "# Ans :-\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')  # For tokenization\n",
        "nltk.download('stopwords')  # If you plan to use stopwords later\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample text\n",
        "text = \"NLTK is a powerful Python library for text processing. NLTK allows easy access to over 50 corpora.\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "words = word_tokenize(text)\n",
        "\n",
        "# Create a frequency distribution of the words\n",
        "fdist = FreqDist(words)\n",
        "\n",
        "# Print the frequency distribution\n",
        "print(fdist)\n",
        "\n",
        "# Plot the frequency distribution\n",
        "fdist.plot(30, cumulative=False)\n",
        "plt.show()\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords data\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Get the list of stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Filter out stopwords from the tokenized words\n",
        "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
        "\n",
        "# Create a frequency distribution of the filtered words\n",
        "fdist_filtered = FreqDist(filtered_words)\n",
        "\n",
        "# Print the filtered frequency distribution\n",
        "print(fdist_filtered)\n",
        "\n",
        "# Plot the frequency distribution\n",
        "fdist_filtered.plot(30, cumulative=False)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!# Q.2 How do you use SpaCy for dependency parsing of a sentence?\n",
        "#Ans :-\n",
        "pip install spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "\n",
        "# Load the pre-trained SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a sentence\n",
        "sentence = \"The quick brown fox jumped over the lazy dog.\"\n",
        "\n",
        "# Process the sentence using SpaCy\n",
        "doc = nlp(sentence)\n",
        "\n",
        "# Print each token and its dependency relation\n",
        "for token in doc:\n",
        "    print(f\"Word: {token.text}, Head: {token.head.text}, Dependency: {token.dep_}\")\n",
        "Word: The, Head: fox, Dependency: det\n",
        "Word: quick, Head: fox, Dependency: amod\n",
        "Word: brown, Head: fox, Dependency: amod\n",
        "Word: fox, Head: jumped, Dependency: nsubj\n",
        "Word: jumped, Head: jumped, Dependency: ROOT\n",
        "Word: over, Head: jumped, Dependency: prep\n",
        "Word: the, Head: dog, Dependency: det\n",
        "Word: lazy, Head: dog, Dependency: amod\n",
        "Word: dog, Head: over, Dependency: pobj\n",
        "Word: ., Head: jumped, Dependency: punct\n",
        "from spacy import displacy\n",
        "\n",
        "# Render the dependency parse in Jupyter Notebook or open in a web browser\n",
        "displacy.render(doc, style='dep', jupyter=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "LBmlUO0fTdOO",
        "outputId": "bc9bb05b-11aa-4287-8d66-f1b786deeb9f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-14-3521db0a6a36>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-3521db0a6a36>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    pip install spacy\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.3 How do you use TextBlob for performing text classification based on polarity?\n",
        "# Ans :-\n",
        "!pip install textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Function to classify text based on polarity\n",
        "def classify_polarity(text):\n",
        "    # Create a TextBlob object\n",
        "    blob = TextBlob(text)\n",
        "\n",
        "    # Get the polarity score\n",
        "    polarity = blob.sentiment.polarity\n",
        "\n",
        "    # Classify the sentiment based on polarity score\n",
        "    if polarity > 0:\n",
        "        return 'Positive'\n",
        "    elif polarity < 0:\n",
        "        return 'Negative'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "# Example sentences\n",
        "texts = [\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"This is the worst experience I've ever had.\",\n",
        "    \"I don't know how I feel about this.\",\n",
        "    \"The service was great and the food was delicious.\"\n",
        "]\n",
        "\n",
        "# Classifying each sentence based on polarity\n",
        "for text in texts:\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {classify_polarity(text)}\")\n",
        "    print('---')\n",
        "Text: I love this product! Its amazing.\n",
        "Sentiment: Positive\n",
        "---\n",
        "Text: This is the worst experience Ive ever had.\n",
        "Sentiment: Negative\n",
        "---\n",
        "Text: I dont know how I feel about this.\n",
        "Sentiment: Neutral\n",
        "---\n",
        "Text: The service was great and the food was delicious.\n",
        "Sentiment: Positive\n",
        "---\n",
        "subjectivity = blob.sentiment.subjectivity\n",
        "print(f\"Subjectivity: {subjectivity}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "wZGhPmUNUNeX",
        "outputId": "16161691-9b41-41f8-c37f-cddaec2644e1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-17-da399118c5b0>, line 35)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-da399118c5b0>\"\u001b[0;36m, line \u001b[0;32m35\u001b[0m\n\u001b[0;31m    Text: I love this product! Its amazing.\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.4 How do you extract named entities from a text using SpaCy\n",
        "# Ans :-\n",
        "!pip install spacy\n",
        "python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "\n",
        "# Load the pre-trained SpaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define a sentence\n",
        "text = \"Apple is looking to buy a startup in the UK for $1 billion. Tim Cook is the CEO of Apple.\"\n",
        "\n",
        "# Process the text using SpaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Extract named entities from the document\n",
        "for entity in doc.ents:\n",
        "    print(f\"Entity: {entity.text}, Label: {entity.label_}\")\n",
        "Entity: Apple, Label: ORG\n",
        "Entity: UK, Label: GPE\n",
        "Entity: $1 billion, Label: MONEY\n",
        "Entity: Tim Cook, Label: PERSON\n",
        "Entity: Apple, Label: ORGfrom spacy import displacy\n",
        "\n",
        "# Render the named entities in the document\n",
        "displacy.render(doc, style='ent', jupyter=True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ewAtIxtaUpk4",
        "outputId": "4e32a01f-d27d-4604-dc45-8664a55ed73f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-32-592fa48248f0>, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-592fa48248f0>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    python -m spacy download en_core_web_sm\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.5 < How can you calculate TF-IDF scores for a given text using Scikit-learn?\n",
        "# Ans :-\n",
        "!pip install scikit-learn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "# Sample text data (documents)\n",
        "texts = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is great for data science.\",\n",
        "    \"Data science involves machine learning and deep learning.\",\n",
        "    \"I love coding and solving problems with Python.\"\n",
        "]\n",
        "\n",
        "# Initialize the TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the text data into a TF-IDF matrix\n",
        "tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "# Convert the TF-IDF matrix into a DataFrame for better readability\n",
        "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "# Print the TF-IDF scores\n",
        "print(df_tfidf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9ph90qyU-8o",
        "outputId": "e64e8e04-5d8a-4598-9e66-f0056e1e9c52"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "        and    coding      data      deep       for     great       in  \\\n",
            "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.57458   \n",
            "1  0.000000  0.000000  0.365594  0.000000  0.463709  0.463709  0.00000   \n",
            "2  0.264801  0.000000  0.264801  0.335866  0.000000  0.000000  0.00000   \n",
            "3  0.331670  0.420681  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
            "\n",
            "   involves        is  learning      love   machine  problems  programming  \\\n",
            "0  0.000000  0.000000  0.000000  0.453005  0.000000  0.000000      0.57458   \n",
            "1  0.000000  0.463709  0.000000  0.000000  0.000000  0.000000      0.00000   \n",
            "2  0.335866  0.000000  0.671732  0.000000  0.335866  0.000000      0.00000   \n",
            "3  0.000000  0.000000  0.000000  0.331670  0.000000  0.420681      0.00000   \n",
            "\n",
            "     python   science   solving      with  \n",
            "0  0.366747  0.000000  0.000000  0.000000  \n",
            "1  0.295980  0.365594  0.000000  0.000000  \n",
            "2  0.000000  0.264801  0.000000  0.000000  \n",
            "3  0.268515  0.000000  0.420681  0.420681  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.6  How do you create a custom text classifier using NLTK's Naive Bayes classifier?\n",
        "# Ans :-\n",
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Sample data: List of (text, label) tuples\n",
        "data = [\n",
        "    (\"I love programming in Python\", \"pos\"),\n",
        "    (\"Python is a great language\", \"pos\"),\n",
        "    (\"I hate bugs in my code\", \"neg\"),\n",
        "    (\"Debugging is fun\", \"pos\"),\n",
        "    (\"This code is full of errors\", \"neg\"),\n",
        "    (\"I enjoy solving problems\", \"pos\"),\n",
        "    (\"This is the worst experience\", \"neg\"),\n",
        "]\n",
        "\n",
        "# Define a function to extract features from a text\n",
        "def extract_features(text):\n",
        "    # Tokenize the text and remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text.lower())\n",
        "    filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "\n",
        "    # Create a frequency distribution of the words\n",
        "    word_freq = FreqDist(filtered_words)\n",
        "\n",
        "    # Return the features as a dictionary of word counts\n",
        "    return {word: True for word in word_freq}\n",
        "\n",
        "# Preprocess the data: Extract features from each text\n",
        "feature_sets = [(extract_features(text), label) for (text, label) in data]\n",
        "\n",
        "# Split the data into a training set and a test set (80% training, 20% test)\n",
        "train_set = feature_sets[:int(0.8 * len(feature_sets))]\n",
        "test_set = feature_sets[int(0.8 * len(feature_sets)):]\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "# Test the classifier\n",
        "test_text = \"I love solving problems in Python\"\n",
        "test_features = extract_features(test_text)\n",
        "\n",
        "# Classify the test text\n",
        "predicted_label = classifier.classify(test_features)\n",
        "\n",
        "print(f\"Text: {test_text}\")\n",
        "print(f\"Predicted Sentiment: {predicted_label}\")\n",
        "# Evaluate the classifier on the test set\n",
        "accuracy = nltk.classify.accuracy(classifier, test_set)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "tjbFnau0Vbwx",
        "outputId": "85f03f96-8be1-4fa2-da6f-2593374d92ad"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-30-c543754ea553>, line 57)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-c543754ea553>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    Predicted Sentiment: pos\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.7  How do you use a pre-trained model from Hugging Face for text classification?\n",
        "# Ans :-\n",
        "!pip install transformers torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the pre-trained DistilBERT model and tokenizer\n",
        "classifier = pipeline(\"text-classification\", model=\"distilbert-base-uncased\", tokenizer=\"distilbert-base-uncased\")\n",
        "\n",
        "# Input text for classification\n",
        "text = \"I love programming in Python. It is an amazing language.\"\n",
        "\n",
        "# Get predictions\n",
        "predictions = classifier(text)\n",
        "\n",
        "# Display the predictions\n",
        "print(predictions)\n",
        "[{'label': 'POSITIVE', 'score': 0.9998607630729675}]\n",
        "classifier = pipeline(\"text-classification\", model=\"bert-base-uncased\", tokenizer=\"bert-base-uncased\")\n",
        "texts = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"I don't like waking up early.\"\n",
        "]\n",
        "\n",
        "predictions = classifier(texts)\n",
        "\n",
        "for text, prediction in zip(texts, predictions):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Prediction: {prediction['label']} (Score: {prediction['score']})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9919d370bf77454ca2456cb503b3f3f5",
            "97ae732e8e1c475aa1b29fdfe2ce11b3",
            "4a2a5a89c6c9496ca7c9c5ad05401e00",
            "35ef22acfa444cdcb6de750e1b45fbba",
            "a73a2ffdf2a64f00a6828e39be66050c",
            "29ead09ae66f4e068aca6a3931903189",
            "b37cbb5babc240bd95f360151f93e125",
            "286847bf3c624c5a852591e83a4e176f",
            "91785c6561d942ca8c1a8009fc948533",
            "27cdfea763de4272ae8684c5f8f3a144",
            "7431c3e6660844c7bd9ccd2b6dd39899",
            "fa9df90f7d8042ba867341e2a4df3592",
            "da24a7f47ac6448e88ef54d17ba94f64",
            "eca786267c6a4026af4db45362c2696e",
            "042584ff8af544f0bcf090fbe83b8dc3",
            "7a1711075b014c49ad9f4b44879d5d74",
            "d4a9e55cad524d2f86001e1e961ac14e",
            "1f6cd44629544f519306e0430768e8ff",
            "4aa67b4948d54baba4872aa3a7a2c631",
            "4a3389aaf1c74526af5d3e5a32315fc6",
            "4a723d57c33f4a329f612e92092e7465",
            "6040bf80727c4b1e8db0d298061b1626",
            "5d399c5262a043729ff13bcb1b5a9662",
            "c8916c90cfca4b9db76665bd86ba05e1",
            "569a7256cfaf47edbfdf3bf22a559a26",
            "325dd91db43245c59f1b25fec4e6a040",
            "ce28d00b5aca4f95a97980c22df9eb3f",
            "3b7916d2b2fe4f6d9978ad85163c3c64",
            "3837d93445d04809a3cd36b04d71808a",
            "dbf5b5f4197a4bd9ab3b0fed55c2ddf4",
            "f2de53edf10547148d7d3a6f917dacfa",
            "a4e01d72b4f84587a8c619d5497931eb",
            "122229d0055347529c03902237cfbb67",
            "8b6d17238fc54adb96c0423e80566843",
            "754ac8ddc79546fb8ea41cbf4f9270de",
            "c43f930284e948bf9c9d8c97672a0ca2",
            "c2258a16cc7e407a92d333ec6ba87ba2",
            "7c5d6d5dd1f94f12b01df410a56e3e26",
            "aa44cb14b2d84dbe8da009a927be49d7",
            "dcad56e7f7234b16994423b454130f99",
            "e915531ac587491cb9a652f94090daf2",
            "ec70875819b3447a9c7be5a20c304b34",
            "f506e7a1976a44f49d35e953a337ae09",
            "cea0baa7407444819a81481e1729c092",
            "069bb4a698144f3f945c87e12064c37b",
            "3a7f9ca0e551433597916ad2e944c9fe",
            "035c23a14d3742adb9ce30d2adda1137",
            "0320382985fd458f8d875ea7352b4eb5",
            "e6d4cc5a8cd9485fa45802e9a6738868",
            "cb0e45e692ec470ca950f9f9aa52027a",
            "4d551c0811de4b458c5e31476a5f5eb5",
            "22684a2d9ed044cdb200f73becaed6c7",
            "e8453ea149b24f11ab014a59afafca3e",
            "54b2b47ab9374a37ab9fa3001d3db61b",
            "72c5086c83e74de7a90f6462de0ca04e",
            "ce8d99d0796349bbbe932311e4687bda",
            "becd8c83a91e4383ba8a36c06947ccc8",
            "d5b2671174ee4527a894347a265b6886",
            "64bfaca9eed74be8ae81d471a9a2332b",
            "3fb6c9a8f46241d6b87b9f167bc26b90",
            "f753a98c95e04182bad06600879eaebc",
            "432e0989bcf2477b8d164277f37538b3",
            "ac47dd07d62b44d59851c8547c0219d0",
            "d577159b477f4b4c81b43a2098a29e73",
            "fb40afe9d5e6421dbde8f0d91094506a",
            "b9e57ab9134f45f4a95a5a12de682d84",
            "1b8fc537a4c44f2692696744a4e4d2ed",
            "d42dc566bdbc4914b639b8929ebe92f5",
            "0294ce4f4da947b5b78f95d7dee7ee99",
            "05b432c9a0cb453d9bafc66aa8451f5f",
            "5c0e3d1c1d7b483cbad13b64f8fb1b9f",
            "3a705ef86a1540cd9ca98d98e2ad6020",
            "6b1b9fcc5135491297e300b5f03e9cbf",
            "65b8a7e5df744570a23ee4d762868e3d",
            "4c342335acc440389389d70e96469910",
            "064b8181d63544be81df54f794da208f",
            "8a163c0913ef412c8206673843601df7",
            "d7003a09e5eb4b7d9edb2eea5a156b5d",
            "5640781d59f34de58a6c5899fbecbeca",
            "2e23a022ac154187a8f6deb63e11ce11",
            "b12ef888798f4a42bc3305cbddbba44d",
            "bd91c7ea94d14ede8fabaf7666e7948a",
            "46e80bd2cf924d4e892505156e093fbc",
            "179a2be90ec8422a81df6c4d87d60584",
            "80bf365a2f074d7698fe11a7c81a2143",
            "02173afe60184c918b37e090bb1add5e",
            "8e7ba33a53ad499b923f8636bd52e0c4",
            "68c274c0ee2144f4b5ee75ecda5e9515",
            "fee1319b28354cf09ac6d94906721bfa",
            "28cf37002ade428585ecfff7031aca8a",
            "7a868c4748294773895d10d56a57ccb4",
            "536b5ade42544898a174824d6d378222",
            "cb196ed9ca3240199a2dadfa579cf08b",
            "794017e6be424936ad1119b92d483dae",
            "e906c27f7b2d4f3884f4f5b0cce5addd",
            "520b2d0df4b540ffae1f4dcbf08aef5f",
            "8ff4b442b4f94ce2855095f2a351a0b6",
            "7c6d8cdd0ce9484bbc9f1ebf09297639",
            "c227affac05944a4b1d26875cbab41bd",
            "a94633263e5e4ca9ae24457216470c48",
            "0c7f8a34318a4c2497e5263a91d0a230",
            "283c2ee623fc452b9a607242ae6a0a1c",
            "ff8b9be3ab734d609f7385f72b12de74",
            "395d9fb859ab446483328acf73cc0efb",
            "f0ce0d7042624e0992d777eab9f6b488",
            "4d224bb73c0c4cc6a143f0180183aaf2",
            "9ba888dc536541839c6e48e532603b3c",
            "e7be4ae79b5f4ad89f1cbd47bbb8c46e",
            "a31ed77956734e59bee3be45121855c8",
            "e9ec51fa7afa4fbbbe17c975c777c465"
          ]
        },
        "id": "LczZa7DRW8d4",
        "outputId": "5d5a2bb6-10a2-4c99-9974-7002b6e135d8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9919d370bf77454ca2456cb503b3f3f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa9df90f7d8042ba867341e2a4df3592"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d399c5262a043729ff13bcb1b5a9662"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b6d17238fc54adb96c0423e80566843"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "069bb4a698144f3f945c87e12064c37b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'LABEL_0', 'score': 0.523686945438385}]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce8d99d0796349bbbe932311e4687bda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b8fc537a4c44f2692696744a4e4d2ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7003a09e5eb4b7d9edb2eea5a156b5d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fee1319b28354cf09ac6d94906721bfa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a94633263e5e4ca9ae24457216470c48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: I love programming in Python.\n",
            "Prediction: LABEL_1 (Score: 0.562480628490448)\n",
            "Text: I don't like waking up early.\n",
            "Prediction: LABEL_1 (Score: 0.6080273389816284)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.9 < How can you create a simple RNN for text classification using Keras?\n",
        "# Ans :-\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample data: list of text and corresponding labels\n",
        "texts = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is a great language for data science.\",\n",
        "    \"I dislike bugs in my code.\",\n",
        "    \"Debugging is fun.\",\n",
        "    \"I hate dealing with errors.\",\n",
        "    \"I enjoy solving complex problems.\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 1, 0, 1]  # 1: positive sentiment, 0: negative sentiment\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to make them the same length\n",
        "X_padded = pad_sequences(X, padding='post')\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the RNN model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=64, input_length=X_train.shape[1]))  # Embedding layer\n",
        "model.add(SimpleRNN(64, activation='tanh'))  # Simple RNN layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=2, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5ZTydotXWQQ",
        "outputId": "438113b0-26be-4160-dbe4-5ef9b3ecd167"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Epoch 1/5\n",
            "\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 14s/step - accuracy: 0.5000 - loss: 0.7280"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x7c19a0e93d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.7245 - val_accuracy: 0.0000e+00 - val_loss: 0.7460\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.8333 - loss: 0.6499 - val_accuracy: 0.0000e+00 - val_loss: 0.7345\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 0.5673 - val_accuracy: 0.0000e+00 - val_loss: 0.7447\n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311ms/step - accuracy: 1.0000 - loss: 0.5369 - val_accuracy: 0.0000e+00 - val_loss: 0.7551\n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366ms/step - accuracy: 1.0000 - loss: 0.4358 - val_accuracy: 0.5000 - val_loss: 0.7678\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.7678\n",
            "Test Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.10 How do you train a Bidirectional LSTM for text classification?\n",
        "# Ans :-\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample data: list of text and corresponding labels\n",
        "texts = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is a great language for data science.\",\n",
        "    \"I dislike bugs in my code.\",\n",
        "    \"Debugging is fun.\",\n",
        "    \"I hate dealing with errors.\",\n",
        "    \"I enjoy solving complex problems.\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 1, 0, 1]  # 1: positive sentiment, 0: negative sentiment\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to make them the same length\n",
        "X_padded = pad_sequences(X, padding='post')\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the Bidirectional LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=64, input_length=X_train.shape[1]))  # Embedding layer\n",
        "model.add(Bidirectional(LSTM(64, activation='tanh')))  # Bidirectional LSTM layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=2, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ip9HHI1XrCv",
        "outputId": "cf41922d-f8fd-4320-c268-c07cecfc76fd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Epoch 1/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 0.6878 - val_accuracy: 0.5000 - val_loss: 0.6914\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.6810 - val_accuracy: 0.5000 - val_loss: 0.6926\n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 1.0000 - loss: 0.6748 - val_accuracy: 0.5000 - val_loss: 0.6948\n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 1.0000 - loss: 0.6668 - val_accuracy: 0.5000 - val_loss: 0.6976\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6976\n",
            "Test Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.11 How do you implement GRU (Gated Recurrent Unit) for text classification?\n",
        "# Ans :-\n",
        "!pip install tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GRU, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Sample data: list of text and corresponding labels\n",
        "texts = [\n",
        "    \"I love programming in Python.\",\n",
        "    \"Python is a great language for data science.\",\n",
        "    \"I dislike bugs in my code.\",\n",
        "    \"Debugging is fun.\",\n",
        "    \"I hate dealing with errors.\",\n",
        "    \"I enjoy solving complex problems.\"\n",
        "]\n",
        "\n",
        "labels = [1, 1, 0, 1, 0, 1]  # 1: positive sentiment, 0: negative sentiment\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "X = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "# Pad sequences to make them the same length\n",
        "X_padded = pad_sequences(X, padding='post')\n",
        "\n",
        "# Convert labels to a numpy array\n",
        "y = np.array(labels)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the GRU model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=64, input_length=X_train.shape[1]))  # Embedding layer\n",
        "model.add(GRU(64, activation='tanh'))  # GRU layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=5, batch_size=2, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG2eAoZJYE0Q",
        "outputId": "bc7191c0-2135-4bf1-ef35-adaa734422de"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Epoch 1/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6949\n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.5000 - loss: 0.6910 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.3333 - loss: 0.6943 - val_accuracy: 0.5000 - val_loss: 0.6989\n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 1.0000 - loss: 0.6862 - val_accuracy: 0.5000 - val_loss: 0.6967\n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.8333 - loss: 0.6823 - val_accuracy: 0.5000 - val_loss: 0.6947\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5000 - loss: 0.6947\n",
            "Test Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.12 How do you implement a text generation model using LSTM with Keras?\n",
        "# Ans :-\n",
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Step 1: Load the text data\n",
        "# Example with a small text corpus (use a larger one for better results)\n",
        "text = \"The quick brown fox jumps over the lazy dog. The quick brown fox is fast.\"\n",
        "\n",
        "# Create a set of unique characters\n",
        "chars = sorted(set(text))\n",
        "char_to_index = {char: index for index, char in enumerate(chars)}\n",
        "index_to_char = {index: char for index, char in enumerate(chars)}\n",
        "\n",
        "# Step 2: Prepare the data for LSTM\n",
        "seq_length = 10  # Length of input sequences (can be adjusted)\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in range(0, len(text) - seq_length):\n",
        "    X.append([char_to_index[char] for char in text[i:i+seq_length]])\n",
        "    y.append(char_to_index[text[i+seq_length]])\n",
        "\n",
        "# Reshape X for LSTM input (samples, time steps, features)\n",
        "X = np.reshape(X, (len(X), seq_length, 1))\n",
        "X = X / float(len(chars))  # Normalize input\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=len(chars))  # One-hot encode target\n",
        "\n",
        "# Step 3: Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.01))\n",
        "\n",
        "# Step 4: Train the model\n",
        "model.fit(X, y, epochs=50, batch_size=128)\n",
        "\n",
        "# Step 5: Generate text after training\n",
        "def generate_text(seed_text, length=100):\n",
        "    generated_text = seed_text\n",
        "    for _ in range(length):\n",
        "        # Prepare input for prediction (last `seq_length` characters)\n",
        "        input_sequence = [char_to_index[char] for char in generated_text[-seq_length:]]\n",
        "        input_sequence = np.reshape(input_sequence, (1, seq_length, 1))\n",
        "        input_sequence = input_sequence / float(len(chars))  # Normalize input\n",
        "\n",
        "        # Predict the next character\n",
        "        prediction = model.predict(input_sequence, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "\n",
        "        # Get the predicted character\n",
        "        next_char = index_to_char[index]\n",
        "        generated_text += next_char\n",
        "    return generated_text\n",
        "\n",
        "# Generate new text\n",
        "seed_text = \"The quick brown\"\n",
        "generated_text = generate_text(seed_text, length=200)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FHsPQKxJYaeA",
        "outputId": "1ecb928a-9dc4-40f6-8377-ee49a52324c5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Argument(s) not recognized: {'lr': 0.01}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-f1f56f708c4f>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Compile the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Step 4: Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, beta_1, beta_2, epsilon, amsgrad, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     ):\n\u001b[0;32m---> 62\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, learning_rate, weight_decay, clipnorm, clipvalue, global_clipnorm, use_ema, ema_momentum, ema_overwrite_frequency, loss_scale_factor, gradient_accumulation_steps, name, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m             )\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Argument(s) not recognized: {kwargs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Argument(s) not recognized: {'lr': 0.01}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q.13 < How do you implement a simple Bi-directional GRU for sequence labeling?\n",
        "# Ans :-\n",
        "!pip install tensorflow\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, GRU, Dense, Dropout, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Example data (you would replace this with your dataset)\n",
        "# A list of sentences with tokens and corresponding labels (NER-style labeling)\n",
        "sentences = [\n",
        "    ['I', 'live', 'in', 'New', 'York'],\n",
        "    ['John', 'is', 'a', 'doctor'],\n",
        "    ['Apple', 'is', 'a', 'tech', 'company']\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    ['O', 'O', 'O', 'B-LOC', 'I-LOC'],  # O=Other, B-LOC=Beginning of location, I-LOC=Inside of location\n",
        "    ['B-PER', 'O', 'O', 'O'],           # B-PER=Beginning of person name\n",
        "    ['B-ORG', 'O', 'O', 'O', 'B-ORG']    # B-ORG=Beginning of organization name\n",
        "]\n",
        "\n",
        "# Create a set of unique words and labels\n",
        "words = list(set(word for sentence in sentences for word in sentence))\n",
        "n_words = len(words)\n",
        "word_to_index = {word: index for index, word in enumerate(words)}\n",
        "\n",
        "labels_set = list(set(label for label_list in labels for label in label_list))\n",
        "n_labels = len(labels_set)\n",
        "label_to_index = {label: index for index, label in enumerate(labels_set)}\n",
        "\n",
        "# Convert sentences and labels into numerical sequences\n",
        "X = [[word_to_index[word] for word in sentence] for sentence in sentences]\n",
        "y = [[label_to_index[label] for label in label_list] for label_list in labels]\n",
        "\n",
        "# Pad sequences to make them of equal length\n",
        "X = pad_sequences(X, padding='post')\n",
        "y = pad_sequences(y, padding='post')\n",
        "\n",
        "# One-hot encode labels\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=n_labels)\n",
        "\n",
        "# Define the Bi-directional GRU model\n",
        "model = Sequential()\n",
        "\n",
        "# Embedding layer to convert words to dense vectors\n",
        "model.add(Embedding(input_dim=n_words, output_dim=64, input_length=X.shape[1]))\n",
        "\n",
        "# Bi-directional GRU layer\n",
        "model.add(Bidirectional(GRU(64, return_sequences=True)))\n",
        "\n",
        "# Dropout layer for regularization\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# Dense layer to output predictions for each token (sequence labeling)\n",
        "model.add(Dense(n_labels, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y, epochs=5, batch_size=2)\n",
        "\n",
        "# Evaluate the model on the same data (typically, you'd have separate test data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPUAvafjY0ty",
        "outputId": "8731ab08-9650-4b6f-b99c-a7c654f44bd5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.12.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.69.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.0889 - loss: 1.6139   \n",
            "Epoch 2/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6000 - loss: 1.5844 \n",
            "Epoch 3/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6000 - loss: 1.5525 \n",
            "Epoch 4/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6000 - loss: 1.5155 \n",
            "Epoch 5/5\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.6000 - loss: 1.4855 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c19ac4eb730>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLmZE4y3ZNv3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}